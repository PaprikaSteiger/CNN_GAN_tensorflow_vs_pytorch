{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnngan_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/blob/master/cnngan_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVn4V5Th08EA"
      },
      "source": [
        "# Implementing a CNNGAN with tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjklIser08EI"
      },
      "source": [
        "## 1. Import and Preprocessing\n",
        "### a) Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW_S35qz08EJ"
      },
      "source": [
        "# Load required packages - data handling & plotting\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Load required packages - deep learning \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beaGqrO_08EK",
        "outputId": "8aaadc52-298c-4fe1-dcb9-a6f082f5c2dc"
      },
      "source": [
        "print(f\"tensorflow: {tf.__version__}\")\n",
        "import sys\n",
        "print(f\"python: {sys.version[:5]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow: 2.4.1\n",
            "python: 3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFAdwWGW08EL"
      },
      "source": [
        "### b) Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3iE76FP08EL"
      },
      "source": [
        "#download and save to file\n",
        "#urllib.request.urlretrieve(\n",
        "#    \"https://media.githubusercontent.com/media/mmeierer/CNN---TensorFlow-vs-PyTorch/main/fashion-mnist_train.csv\",\n",
        "#    \"fashion-mnist_train.csv\")\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "del y_train\n",
        "del x_test\n",
        "del y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I9TNMoN08EM"
      },
      "source": [
        "#train_data = pd.read_csv('https://media.githubusercontent.com/media/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/master/fashion-mnist_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "-Ap43CSl08EM",
        "scrolled": true,
        "outputId": "5d0f22d9-ca33-4ac5-95c8-06b28afbcfbe"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>211</td>\n",
              "      <td>220</td>\n",
              "      <td>214</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>222</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>214</td>\n",
              "      <td>163</td>\n",
              "      <td>146</td>\n",
              "      <td>165</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>183</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>102</td>\n",
              "      <td>165</td>\n",
              "      <td>160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>163</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>249</td>\n",
              "      <td>207</td>\n",
              "      <td>197</td>\n",
              "      <td>202</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>69</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>136</td>\n",
              "      <td>147</td>\n",
              "      <td>144</td>\n",
              "      <td>121</td>\n",
              "      <td>102</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "2      6       0       0       0  ...         0         0         0         0\n",
              "3      0       0       0       0  ...         0         0         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KNtIlIw08EN"
      },
      "source": [
        "train_images = train_data.iloc[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LWQUkTRs08EO",
        "outputId": "e660a9bd-7e4e-4282-f158-cb854d52b7a7"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images.values[0].reshape(28,28), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Fjydps08EP"
      },
      "source": [
        "### c) Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmUTCQY108EP"
      },
      "source": [
        "# use maximum normalization\n",
        "train_images = train_images / np.float32(255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "OjoHiD2108EP",
        "outputId": "a0d73689-03e7-4bd4-e805-bd7dcc4b5111"
      },
      "source": [
        "train_images.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>pixel40</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.360784</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.419608</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.890196</td>\n",
              "      <td>...</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.862745</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.749020</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.976471</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.772549</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086275</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180392</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.929412</td>\n",
              "      <td>0.898039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.454902</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3    pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "1     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "2     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "3     0.0     0.0     0.0  0.003922  ...       0.0       0.0       0.0       0.0\n",
              "4     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhN_PtQy08EQ"
      },
      "source": [
        "\n",
        "## 2. Model specific data preparation (tensorflow)\n",
        "## a) Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8aME-e308EQ"
      },
      "source": [
        "x_train_tf = tf.convert_to_tensor(train_images.values.reshape((-1, 28, 28, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_mW_cI2U08ER",
        "outputId": "02dcce4e-37bf-4c46-cfb1-cec9b04c0aac"
      },
      "source": [
        "# use random seed to create fake input data\n",
        "seed = tf.random.uniform([28,28], 0, 1, tf.float32)\n",
        "seed_im = seed.numpy() * 255\n",
        "plt.figure()\n",
        "plt.imshow(seed_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhZkXM5808ER"
      },
      "source": [
        "### b) Tensor view of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrsVbeoH08ER",
        "outputId": "3893b89b-8c7b-4ec9-9c81-a797ba435c75"
      },
      "source": [
        "x_train_tf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 28, 28, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5qhF5O608ES",
        "outputId": "956c03c2-62fc-407c-83e3-a64e3305e8b5"
      },
      "source": [
        "seed.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16VSHG8D08ES",
        "outputId": "8a5d8496-b645-44f8-8beb-8e1ec585e936"
      },
      "source": [
        "x_train_tf[0][5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28, 1), dtype=float32, numpy=\n",
              "array([[0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.18431373],\n",
              "       [0.9882353 ],\n",
              "       [0.91764706],\n",
              "       [0.93333334],\n",
              "       [0.8784314 ],\n",
              "       [0.84313726],\n",
              "       [0.84313726],\n",
              "       [0.8980392 ],\n",
              "       [0.42352942],\n",
              "       [0.7058824 ],\n",
              "       [0.8117647 ],\n",
              "       [0.8392157 ],\n",
              "       [0.8784314 ],\n",
              "       [0.90588236],\n",
              "       [0.9764706 ],\n",
              "       [0.99607843],\n",
              "       [0.1764706 ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsBm_3fk08ET"
      },
      "source": [
        "## 3. Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smxDxyDs08ET"
      },
      "source": [
        "### a.1) Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0oL5-4c08ET"
      },
      "source": [
        "# for weight initialization\n",
        "initializer_nn = tf.random_uniform_initializer(minval=-1, maxval=1, seed=123)\n",
        "def generator_model():   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(keras.layers.Conv2DTranspose(64, (7,7), input_shape=(1, 1, 100), strides=1, padding='valid', use_bias=True, name=\"Conv2D1\"))\n",
        "    model.add(keras.layers.BatchNormalization(name=\"Batchnorm1\"))\n",
        "    model.add(keras.layers.LeakyReLU(name=\"LeakyRelu1\"))\n",
        "    assert model.output_shape == (None, 7, 7, 64)\n",
        "\n",
        "    model.add(keras.layers.Conv2DTranspose(32, (8, 8), strides=(1, 1), padding='valid', use_bias=True, name=\"Conv2D2\"))\n",
        "    assert model.output_shape == (None, 14, 14, 32)\n",
        "    model.add(keras.layers.BatchNormalization(name=\"Batchnorm2\"))\n",
        "    model.add(keras.layers.LeakyReLU(name=\"LeakyRelu2\"))\n",
        "\n",
        "    model.add(keras.layers.Conv2DTranspose(1, (15, 15), strides=(1, 1), padding='valid', use_bias=True, name=\"Conv2D3\"))\n",
        "    model.add(keras.layers.Activation(keras.activations.sigmoid, name=\"Sigmoid1\"))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "generator = generator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8l3mz4608EU",
        "outputId": "ee4bf4ca-3987-41cb-8127-85306ea18b4f"
      },
      "source": [
        "# generated image not trained\n",
        "fake_im_not_trained = generator(tf.random.normal([1, 1, 1, 100], 0, 1, tf.float32))\n",
        "fake_im_not_trained.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 28, 28, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEN0m5oH08EV"
      },
      "source": [
        "###  a.2) Inspect the generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcl5DfBm08EV",
        "outputId": "3d57761c-811f-4b1f-af06-a4ce45924434"
      },
      "source": [
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv2D1 (Conv2DTranspose)    (None, 7, 7, 64)          313664    \n",
            "_________________________________________________________________\n",
            "Batchnorm1 (BatchNormalizati (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "LeakyRelu1 (LeakyReLU)       (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "Conv2D2 (Conv2DTranspose)    (None, 14, 14, 32)        131104    \n",
            "_________________________________________________________________\n",
            "Batchnorm2 (BatchNormalizati (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "LeakyRelu2 (LeakyReLU)       (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv2D3 (Conv2DTranspose)    (None, 28, 28, 1)         7201      \n",
            "_________________________________________________________________\n",
            "Sigmoid1 (Activation)        (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 452,353\n",
            "Trainable params: 452,161\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfL33kgx08EV"
      },
      "source": [
        "### a.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fARY_Jx08EW",
        "outputId": "a6dda4be-5b02-4474-a4ac-10c54c82343e"
      },
      "source": [
        "hidden1_tf_ante = generator.layers[0]\n",
        "weights_tf_ante, biases_tf_ante = hidden1_tf_ante.get_weights()\n",
        "weights_tf_ante[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1.17349569e-02,  1.97003502e-02,  3.37529555e-03, ...,\n",
              "         -1.83218680e-02,  1.75963696e-02, -2.57165506e-02],\n",
              "        [ 1.88944321e-02,  2.58057192e-03, -5.91061078e-03, ...,\n",
              "         -3.38664465e-03,  1.09844487e-02, -1.01208780e-02],\n",
              "        [ 2.44344193e-02, -9.35407542e-03,  1.55514833e-02, ...,\n",
              "          2.46017445e-02, -7.24623911e-03, -1.23612834e-02],\n",
              "        ...,\n",
              "        [ 1.32317077e-02,  2.12547686e-02,  1.80099253e-02, ...,\n",
              "          1.96534023e-03,  1.38101708e-02,  1.76015105e-02],\n",
              "        [ 1.05215982e-03, -2.31731683e-05,  4.23604809e-03, ...,\n",
              "          6.09599240e-03,  1.45365428e-02, -4.79436480e-03],\n",
              "        [-3.79423797e-03,  1.30658839e-02, -1.03510041e-02, ...,\n",
              "          1.56574566e-02, -1.36418883e-02, -9.05726478e-03]],\n",
              "\n",
              "       [[ 3.24024633e-03,  2.20413674e-02, -8.96912813e-03, ...,\n",
              "          2.66891997e-02, -1.22363577e-02,  2.44430844e-02],\n",
              "        [ 2.19134260e-02,  4.84880991e-03, -2.72823237e-02, ...,\n",
              "          7.30694272e-03, -1.62058882e-03,  1.91388447e-02],\n",
              "        [ 2.02147271e-02,  6.00639544e-03,  4.23612632e-03, ...,\n",
              "         -1.80911031e-02, -1.04499366e-02,  8.81974585e-03],\n",
              "        ...,\n",
              "        [-1.62751414e-03, -2.20419746e-02,  3.03490832e-03, ...,\n",
              "         -2.37810854e-02,  2.55368669e-02,  2.07952131e-02],\n",
              "        [-7.75850937e-03, -1.59564316e-02,  1.96115430e-02, ...,\n",
              "          2.71880310e-02,  2.57832278e-02,  1.75310727e-02],\n",
              "        [-2.44258083e-02,  4.39217128e-03,  2.10875627e-02, ...,\n",
              "          2.62681264e-02,  1.55275930e-02,  7.76502676e-03]],\n",
              "\n",
              "       [[-8.17604549e-03, -1.21941548e-02,  2.58656591e-03, ...,\n",
              "         -2.36608088e-03,  7.65303150e-04,  1.27992760e-02],\n",
              "        [-1.61694046e-02, -1.04354210e-02,  2.50910595e-03, ...,\n",
              "         -1.21593857e-02, -1.80294551e-02,  2.33150106e-02],\n",
              "        [-1.73954032e-02,  1.17214676e-02,  2.34308857e-02, ...,\n",
              "          1.24196801e-02,  1.18448939e-02,  6.06697053e-04],\n",
              "        ...,\n",
              "        [-2.34920140e-02, -1.46212988e-02, -1.88755617e-03, ...,\n",
              "         -1.13607533e-02, -2.62636319e-03, -1.07990410e-02],\n",
              "        [ 4.75773402e-03,  3.51526402e-03, -1.41045833e-02, ...,\n",
              "         -2.23622285e-03, -1.84399858e-02, -1.37393810e-02],\n",
              "        [-1.39652723e-02, -2.62660906e-04, -7.41758198e-03, ...,\n",
              "          1.17179472e-02, -1.83180235e-02, -2.06859950e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 2.12931652e-02,  2.04761829e-02,  2.78596207e-03, ...,\n",
              "          1.35771986e-02,  8.27526487e-03,  1.99716557e-02],\n",
              "        [-4.60733287e-03,  2.20392700e-02,  1.84502918e-02, ...,\n",
              "          8.56842659e-03, -1.24469064e-02,  1.05671491e-02],\n",
              "        [ 2.59916987e-02, -8.33107531e-03,  1.93954203e-02, ...,\n",
              "         -2.34994031e-02,  6.86630048e-03, -1.28173660e-02],\n",
              "        ...,\n",
              "        [ 2.54073236e-02,  7.15763308e-03, -2.03033201e-02, ...,\n",
              "         -2.28452198e-02,  2.31075864e-02, -5.50076924e-03],\n",
              "        [-1.41625777e-02, -1.86012257e-02,  4.09177132e-03, ...,\n",
              "          2.55041588e-02, -1.43103050e-02,  1.88823175e-02],\n",
              "        [-1.87364183e-02, -2.33812053e-02,  2.26827431e-02, ...,\n",
              "         -5.17669506e-03,  1.98296998e-02, -6.95921853e-03]],\n",
              "\n",
              "       [[ 1.65639948e-02,  3.45145911e-03, -1.84594002e-02, ...,\n",
              "          1.47600677e-02,  6.69484399e-03,  3.24934721e-03],\n",
              "        [-2.68378183e-02, -1.63619779e-03,  2.67823990e-02, ...,\n",
              "          2.59142537e-02, -7.46205077e-03,  1.89867336e-02],\n",
              "        [-2.72449758e-02, -1.16060190e-02,  3.60552035e-03, ...,\n",
              "         -2.41247304e-02, -2.40904242e-02, -2.20522098e-02],\n",
              "        ...,\n",
              "        [-9.77767631e-03,  9.05101933e-03,  6.83622248e-03, ...,\n",
              "          2.65718568e-02,  1.45512801e-02,  3.52400728e-03],\n",
              "        [-1.26374690e-02, -2.52219662e-02,  5.62161766e-03, ...,\n",
              "          6.94543123e-05,  1.14313532e-02,  2.50469539e-02],\n",
              "        [-1.41505906e-02,  1.08032618e-02, -7.12095946e-03, ...,\n",
              "         -2.87555903e-03,  2.53814328e-02,  2.24878695e-02]],\n",
              "\n",
              "       [[-8.31929781e-03,  5.13817184e-03,  6.60487823e-03, ...,\n",
              "          2.67875623e-02, -2.30425000e-02,  2.43428033e-02],\n",
              "        [-1.30809126e-02, -2.31464282e-02, -2.65568681e-03, ...,\n",
              "          1.93122942e-02, -5.99939190e-03,  2.70984005e-02],\n",
              "        [ 1.55645665e-02,  7.59985112e-03, -1.71406642e-02, ...,\n",
              "          1.18811037e-02, -6.36772253e-03, -1.07384920e-02],\n",
              "        ...,\n",
              "        [ 2.43164916e-02,  2.51719262e-02,  1.37755964e-02, ...,\n",
              "         -3.13367881e-03,  1.29077639e-02,  1.82967391e-02],\n",
              "        [-8.78416188e-03,  1.46904979e-02,  2.64170971e-02, ...,\n",
              "          2.00694147e-02, -8.23174603e-03,  1.37835182e-03],\n",
              "        [-1.64105259e-02, -1.43778045e-02,  7.15638883e-03, ...,\n",
              "         -1.93885416e-02, -1.46809733e-02,  1.82517562e-02]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2q3RUxl08EW",
        "outputId": "0b6c6912-d050-40a7-d6bf-a569b18a409c"
      },
      "source": [
        "weights_tf_ante[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 64, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKVbWazO08EW",
        "outputId": "f344c4f7-01fe-43f9-a996-b93efc47b123"
      },
      "source": [
        "biases_tf_ante"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtFoWQUE08EX",
        "outputId": "08a3f96f-ec7c-406f-cf33-7e0fad2486da"
      },
      "source": [
        "biases_tf_ante.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3VSO3Th08EX"
      },
      "source": [
        "### b.1) Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKbOs-Jl08EX"
      },
      "source": [
        "def discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(input_shape=(28,28,1), filters=2, kernel_size=5, strides=1, padding=\"same\", name=\"Conv2D1\"))\n",
        "    model.add(keras.layers.AveragePooling2D(pool_size=2, strides=2, name=\"Pooling1\"))\n",
        "    model.add(keras.layers.LeakyReLU(name=\"LeakyRelu1\"))\n",
        "    model.add(keras.layers.Dropout(0.3, name=\"Dropout1\"))\n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters=2, kernel_size=5, strides=1, padding=\"same\", name=\"Conv2D2\"))\n",
        "    model.add(keras.layers.LeakyReLU(name=\"LeakyRelu2\"))\n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters=1, kernel_size=5, strides=1, name=\"conv2D3\"))\n",
        "    model.add(keras.layers.LeakyReLU(name=\"LeakyRelu3\"))\n",
        "    \n",
        "    model.add(keras.layers.Flatten(name=\"Flatten1\"))\n",
        "    \n",
        "    model.add(keras.layers.Dense(100, kernel_initializer=initializer_nn, name=\"Dense1\"))\n",
        "    model.add(keras.layers.LeakyReLU(name=\"LeakyRelu4\"))\n",
        "    \n",
        "    model.add(keras.layers.Dense(64, kernel_initializer=initializer_nn, name=\"Dense2\"))\n",
        "    model.add(keras.layers.Activation(keras.activations.tanh, name=\"Tanh\"))\n",
        "    \n",
        "    model.add(keras.layers.Dense(1, kernel_initializer=initializer_nn, name=\"Dense3\"))\n",
        "    model.add(keras.layers.Activation(keras.activations.sigmoid, name=\"Sigmoid\"))\n",
        "    return model\n",
        "discriminator = discriminator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwxd4Ete08EY"
      },
      "source": [
        "### b.2) Inspect the discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6lb0J6h08EY",
        "outputId": "e8e65b5f-461b-4961-b521-39cfd102cc5f"
      },
      "source": [
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv2D1 (Conv2D)             (None, 28, 28, 2)         52        \n",
            "_________________________________________________________________\n",
            "Pooling1 (AveragePooling2D)  (None, 14, 14, 2)         0         \n",
            "_________________________________________________________________\n",
            "LeakyRelu1 (LeakyReLU)       (None, 14, 14, 2)         0         \n",
            "_________________________________________________________________\n",
            "Dropout1 (Dropout)           (None, 14, 14, 2)         0         \n",
            "_________________________________________________________________\n",
            "Conv2D2 (Conv2D)             (None, 14, 14, 2)         102       \n",
            "_________________________________________________________________\n",
            "LeakyRelu2 (LeakyReLU)       (None, 14, 14, 2)         0         \n",
            "_________________________________________________________________\n",
            "conv2D3 (Conv2D)             (None, 10, 10, 1)         51        \n",
            "_________________________________________________________________\n",
            "LeakyRelu3 (LeakyReLU)       (None, 10, 10, 1)         0         \n",
            "_________________________________________________________________\n",
            "Flatten1 (Flatten)           (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Dense1 (Dense)               (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "LeakyRelu4 (LeakyReLU)       (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Dense2 (Dense)               (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "Tanh (Activation)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "Dense3 (Dense)               (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "Sigmoid (Activation)         (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 16,834\n",
            "Trainable params: 16,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMIbdfSn08EZ"
      },
      "source": [
        "### b.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43yNJmKR08EZ",
        "outputId": "af57030d-ff6a-41a5-80bd-a04d4701009d"
      },
      "source": [
        "hidden2_tf_ante = discriminator.layers[0]\n",
        "weights2_tf_ante, biases2_tf_ante = hidden2_tf_ante.get_weights()\n",
        "weights2_tf_ante[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.08929583,  0.05092797]],\n",
              "\n",
              "       [[ 0.24591658, -0.02951244]],\n",
              "\n",
              "       [[ 0.28247198, -0.13832097]],\n",
              "\n",
              "       [[ 0.1410583 ,  0.08244011]],\n",
              "\n",
              "       [[ 0.09257513,  0.00590676]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGtYVoN608EZ",
        "outputId": "aa2910c9-60cf-417a-a4fe-48ccacdc85f3"
      },
      "source": [
        "biases2_tf_ante"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOD7qimU08Ea"
      },
      "source": [
        "## 4. Loss & Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gaOeazm08Eb"
      },
      "source": [
        "### 4.a) Generator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csOFw1lN08Eb"
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits='activation')\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64yCgpdk08Eb"
      },
      "source": [
        "### 4.b) Discriminator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysMQ5I-w08Eb"
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzeYUdNv08Ec"
      },
      "source": [
        "## 4.c) Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxBEXFa208Ec"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy') # only for discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36GcMCx808Ec"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AklBYLJ_08Ec"
      },
      "source": [
        "# for saving the model\n",
        "import os\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E-e_So108Ed"
      },
      "source": [
        "# This annotation causes the function to be \"compiled\".\n",
        "#@tf.function\n",
        "def train_step_tf(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size = 100):\n",
        "    gen_losses = []\n",
        "    disc_losses = []\n",
        "    for beg_i in range(0, x_train_tf.shape[0], batch_size):\n",
        "        x_train_batch_tf = x_train_tf[beg_i:beg_i + batch_size]\n",
        "\n",
        "        x_fake_batch_tf = tf.random.normal([batch_size, 1, 1, 100], 0, 1, tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "            generated_images = generator( x_fake_batch_tf, training=True)\n",
        "            real_output = discriminator(x_train_batch_tf, training=True)\n",
        "            fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "            gen_loss = generator_loss(fake_output)\n",
        "            disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "        \n",
        "        gen_losses.append(gen_loss)\n",
        "        disc_losses.append(disc_loss)\n",
        "        \n",
        "        train_accuracy.update_state(tf.ones_like(real_output), real_output)\n",
        "        train_accuracy.update_state(tf.zeros_like(fake_output), fake_output)\n",
        "    return gen_losses, disc_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "1u9bWcEM08Ed",
        "scrolled": false,
        "outputId": "ecdbdc4c-1abc-4d65-c571-c2ca3b2d0843"
      },
      "source": [
        "train_losses_generator_tf = []\n",
        "train_losses_discriminator_tf = []\n",
        "train_acc_discriminator_tf = []\n",
        "epochs = 15\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    gen_loss, disc_loss = train_step_tf(generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
        "    train_loss_generator_tf = float(tf.reduce_mean(gen_loss))\n",
        "    train_loss_discriminator_tf = float(tf.reduce_mean(disc_loss))\n",
        "    train_losses_generator_tf.append(train_loss_generator_tf)\n",
        "    train_losses_discriminator_tf.append(train_loss_discriminator_tf)\n",
        "\n",
        "    template = (\"Epoch {}, Loss_Generator: {}, Loss_Discriminator: {}, Discriminator_Accuracy: {}\")\n",
        "    print(template.format(epoch+1, train_loss_generator_tf, train_loss_discriminator_tf, train_accuracy.result()*100))\n",
        "    train_acc_discriminator_tf.append(train_accuracy.result()*100)\n",
        "    train_accuracy.reset_states()\n",
        "end = time.time()\n",
        "print(f\"Total training time{(end - start)/60.0}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss_Generator: 0.9152773022651672, Loss_Discriminator: 1.4088431596755981, Discriminator_Accuracy: 65.7366714477539\n",
            "Epoch 2, Loss_Generator: 0.8600758910179138, Loss_Discriminator: 1.2255518436431885, Discriminator_Accuracy: 67.36083984375\n",
            "Epoch 3, Loss_Generator: 0.9105566143989563, Loss_Discriminator: 1.2490020990371704, Discriminator_Accuracy: 63.94666290283203\n",
            "Epoch 4, Loss_Generator: 0.8423505425453186, Loss_Discriminator: 1.2504206895828247, Discriminator_Accuracy: 65.88333129882812\n",
            "Epoch 5, Loss_Generator: 0.9626114964485168, Loss_Discriminator: 1.177001714706421, Discriminator_Accuracy: 67.54750061035156\n",
            "Epoch 6, Loss_Generator: 2.1399731636047363, Loss_Discriminator: 0.7356869578361511, Discriminator_Accuracy: 84.69083404541016\n",
            "Epoch 7, Loss_Generator: 2.1231014728546143, Loss_Discriminator: 0.7090948224067688, Discriminator_Accuracy: 84.6241683959961\n",
            "Epoch 8, Loss_Generator: 2.2293736934661865, Loss_Discriminator: 0.6851399540901184, Discriminator_Accuracy: 85.5191650390625\n",
            "Epoch 9, Loss_Generator: 0.9342195391654968, Loss_Discriminator: 1.2809500694274902, Discriminator_Accuracy: 64.8183364868164\n",
            "Epoch 10, Loss_Generator: 0.8320685029029846, Loss_Discriminator: 1.2939746379852295, Discriminator_Accuracy: 62.304996490478516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e536d349416f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loss_generator_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss_discriminator_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-5cb42b310791>\u001b[0m in \u001b[0;36mtrain_step_tf\u001b[0;34m(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mgradients_of_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_zeros\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m    670\u001b[0m   \u001b[0;34m\"\"\"Helper to return (possibly cached) zero tensors in eager mode.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m   \u001b[0;31m# Note: variants will use _zeros_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC7R0vYU08Ee"
      },
      "source": [
        "### b) Training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZGyw6Q508Ee"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(train_acc_discriminator_tf)\n",
        "plt.title('discriminator accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['discriminator_train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKDOIkXr08Ef"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(train_losses_generator_tf)\n",
        "plt.plot(train_losses_discriminator_tf)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['generator', 'discriminator'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-mqVig08Ef",
        "scrolled": true
      },
      "source": [
        "print(train_losses_generator_tf)\n",
        "print(train_losses_discriminator_tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdK-aJG708Eg"
      },
      "source": [
        "### c1) Generator output before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7es9wgMR08Eg"
      },
      "source": [
        "fake_im_not_trained = fake_im_not_trained.numpy() * 255\n",
        "fake_im_not_trained = fake_im_not_trained.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im_not_trained, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd6RVvyt08Eh"
      },
      "source": [
        "### c2) Generator output after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV1YlKbU08Eh",
        "scrolled": true
      },
      "source": [
        "seed2 = tf.random.uniform([1, 1, 1, 100], 0, 1, tf.float32)\n",
        "fake_im = generator(seed2, training=False)\n",
        "fake_im = fake_im.numpy() * 255\n",
        "fake_im = fake_im.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK9A2_C_08Eh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}