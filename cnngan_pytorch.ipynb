{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnngan_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/blob/master/cnngan_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVotrWM-065f"
      },
      "source": [
        "# Implementing a CNNGAN with pytroch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt9oTYk6065n"
      },
      "source": [
        "## 1. Import and Preprocessing\n",
        "### a) Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOvHT87j065o"
      },
      "source": [
        "# Load required packages - data handling & plotting\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Load required packages - deep learning \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2kizsA7065p",
        "outputId": "bba49e97-47a1-439a-e949-5dae9c29f91f"
      },
      "source": [
        "print(f\"tensorflow: {torch.__version__}\")\n",
        "import sys\n",
        "print(f\"python: {sys.version[:5]}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow: 1.8.1+cu101\n",
            "python: 3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7um10LNJ065q"
      },
      "source": [
        "### b) Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOi4NVI065r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806cddd9-8392-4511-dd3c-94d3d7a19695"
      },
      "source": [
        "# I exceeded my git LFS bandwidth limit for this month, thus the file cannot be loaded from git\n",
        "#train_data = pd.read_csv('https://media.githubusercontent.com/media/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/master/fashion-mnist_train.csv')\n",
        "\n",
        "# load directly from keras and transform to pandas\n",
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "y_train = y_train.reshape((-1,1))\n",
        "x_train = x_train.reshape((-1, 28*28))\n",
        "x_train = np.concatenate([y_train, x_train], axis=1)\n",
        "labels = [\"label\"] + [f\"pixel{i}\" for i in range(1,785)]\n",
        "train_data = pd.DataFrame(x_train,columns=labels, index=list(range(60000)))\n",
        "del x_train\n",
        "del y_train\n",
        "del x_test\n",
        "del y_test\n",
        "\n",
        "# or load from git repo from mmeirer\n",
        "#train_data = pd.read_csv('https://media.githubusercontent.com/media/mmeierer/CNN---TensorFlow-vs-PyTorch/main/fashion-mnist_train.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukf4AIqY065r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "c7291586-25f5-4c0a-86af-ed583a831c31"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>188</td>\n",
              "      <td>103</td>\n",
              "      <td>54</td>\n",
              "      <td>48</td>\n",
              "      <td>43</td>\n",
              "      <td>87</td>\n",
              "      <td>168</td>\n",
              "      <td>133</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>136</td>\n",
              "      <td>219</td>\n",
              "      <td>216</td>\n",
              "      <td>...</td>\n",
              "      <td>244</td>\n",
              "      <td>240</td>\n",
              "      <td>243</td>\n",
              "      <td>214</td>\n",
              "      <td>224</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>146</td>\n",
              "      <td>130</td>\n",
              "      <td>135</td>\n",
              "      <td>135</td>\n",
              "      <td>137</td>\n",
              "      <td>125</td>\n",
              "      <td>124</td>\n",
              "      <td>125</td>\n",
              "      <td>121</td>\n",
              "      <td>119</td>\n",
              "      <td>114</td>\n",
              "      <td>130</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>118</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>88</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>212</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>102</td>\n",
              "      <td>75</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>56</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>96</td>\n",
              "      <td>175</td>\n",
              "      <td>156</td>\n",
              "      <td>64</td>\n",
              "      <td>14</td>\n",
              "      <td>54</td>\n",
              "      <td>137</td>\n",
              "      <td>204</td>\n",
              "      <td>194</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>186</td>\n",
              "      <td>177</td>\n",
              "      <td>183</td>\n",
              "      <td>175</td>\n",
              "      <td>...</td>\n",
              "      <td>83</td>\n",
              "      <td>152</td>\n",
              "      <td>85</td>\n",
              "      <td>160</td>\n",
              "      <td>133</td>\n",
              "      <td>100</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>206</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>242</td>\n",
              "      <td>255</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>102</td>\n",
              "      <td>168</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>161</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      9       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      0       0       0       0  ...         0         0         0         0\n",
              "3      3       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqXVdux_065s"
      },
      "source": [
        "train_images = train_data.iloc[:,1:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54zxTjsL065s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6d2f2895-566a-49cb-9294-9dec677b992e"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images.values[0].reshape(28,28), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaCUlEQVR4nO3dfYxV1bnH8e9TQN7LqyDiVHyBtPQNLfXaao3U2gvmpqhNqDZpudUW02iuJja51n9qYkyNrXpr4jUZXyImWi+JesWG1nKJiTXUFyAEEG6vSDGC4yBCkVd18Ll/nD3tgTN7rT1z3vYafp/kZM7s5+yz1+wZHtZe59lrmbsjIpKqT7W7ASIi9VASE5GkKYmJSNKUxEQkaUpiIpK0oa08mJnpo1CRJnN3q2f/+fPn++7duwu9du3atc+7+/x6jlevupKYmc0HfgMMAR5y9zsb0ioRaZvdu3ezZs2aQq81s8lNbk7UgC8nzWwIcD+wAJgNXG1msxvVMBFpH3cv9Igxsw4ze8HMNpvZ62Z2Y7b9NjPbaWbrs8dlVfv83My2mtlfzOyfY8eopyd2HrDV3bdlB34SWAhsruM9RaQEPvnkk0a9VQ9ws7uvM7OxwFozW5nF7nX3X1e/OOsIXQV8HjgV+B8zm+XuR/MOUM/A/nTg7arvd2TbjmFmS8xsjZkV65+KSFsV7YUV6Ym5e5e7r8ue7we20EeeqLIQeNLdP3T3vwJbqXSYcjX900l373T3ue4+t9nHEpHG6EcSm9zbSckeS/Le08xmAOcAr2SbbjCzDWb2iJlNyLYV6hxVqyeJ7QQ6qr4/LdsmIonrRxLb3dtJyR6dfb2fmY0BngJucvcPgAeAs4A5QBdw90DbWk8Sew2YaWZnmNlJVK5jl9fxfiJSEo26nAQws2FUEtjj7v509v7d7n7U3T8BHuQfl4z97hwNOIm5ew9wA/A8levcZe7++kDfT0TKo4GfThrwMLDF3e+p2j6t6mVXAJuy58uBq8xsuJmdAcwEXg0do646MXdfAayo5z1EpFzcvZGfTl4A/ADYaGbrs223UinJmgM4sB24Ljv262a2jEqVQw9wfeiTSWhxxb6IpKFR8wy6+0tAX3cQ5HZ+3P0O4I6ix1ASE5EaKU2WqiQmIjWUxEQkWf355LEMlMREpEYDB/abTklMRGqoJyYiydLlpIgkT0lMRJKmJCYiSVMSE5FkNfi2o6ZTEhORGuqJiUjSlMSkNCozoeSr94917NixwfiFF16YG/v9739f17FjP9uQIUNyYz09PXUdu16xtoe0IsEoiYlI0pTERCRZGtgXkeSpJyYiSVMSE5GkKYmJSLJ0A7iIJE9JTErjU58Kr8p39GhwIRnOPvvsYPzHP/5xMH748OHc2MGDB4P7HjlyJBh/9dXgSl511YLF6rhi5zW2fz1tC9W/xX6fRenTSRFJmnpiIpIsjYmJSPKUxEQkaUpiIpI0JTERSZbunRSR5KknJqURqimCeF3RN7/5zWD8W9/6VjC+Y8eO3Njw4cOD+44aNSoYv/TSS4Pxhx56KDfW3d0d3Df2j7jeeqwxY8bkxmK9oEOHDtV17CJOmCRmZtuB/cBRoMfd5zaiUSLSXidMEsvMc/fdDXgfESmJEy2JicggktrAfvgGsDgH/mhma81sSV8vMLMlZrbGzNbUeSwRaZHeqv3YowzqTWIXuvu5wALgejO76PgXuHunu8/VeJlIOhqVxMysw8xeMLPNZva6md2YbZ9oZivN7I3s64Rsu5nZfWa21cw2mNm5sWPUlcTcfWf2dRfwDHBePe8nIuXQwJ5YD3Czu88GzqfS2ZkN3AKscveZwKrse6h0iGZmjyXAA7EDDDiJmdloMxvb+xz4NrBpoO8nIuVQNIEVSWLu3uXu67Ln+4EtwHRgIbA0e9lS4PLs+ULgMa94GRhvZtNCx6hnYH8q8Ew2b9JQ4Al3/0Md7ydN8NFHH9W1/1e/+tVgfMaMGcF4qE4tNifX888/H4yfc845wfhdd92VG1uzJjxEu3HjxmB8y5Ytwfh554UvSkLndfXq1cF9//znP+fGDhw4ENy3qH6Md00+bry70907+3qhmc0AzgFeAaa6e1cWepdKPoFKgnu7arcd2bYucgw4ibn7NuDLA91fRMqrH59O7i4y3m1mY4CngJvc/YPqSSPd3c1swJ8S1DuwLyKDUCM/nTSzYVQS2OPu/nS2ubv3MjH7uivbvhPoqNr9tGxbLiUxETlGI8fErNLlehjY4u73VIWWA4uz54uBZ6u2/zD7lPJ8YF/VZWefVOwqIjUaWAN2AfADYKOZrc+23QrcCSwzs2uBt4BFWWwFcBmwFTgE/Ch2ACUxEanRqCTm7i8BeaumXNLH6x24vj/HUBITkRplqcYvQklsEAgtDxb7Y4xNZzN3bviDp/379wfjo0ePzo3NmjUruG8s/tprrwXjW7duzY2FpsIB+NrXvhaMX3nllcH4xx9/HIyH2h5bBu/DDz/MjcVKR4pI7d5JJTERqaGemIgkTUlMRJKmJCYiSVMSE5FkaWBfRJKnnpiIJC2lJGatbGw9d6oPZqE6r3rFfr8vv/xyMB6baicm9LP19PQE9613GqEjR47kxmKXS+vWrQvGQzVoEP/Z5s+fnxs788wzg/tOnz49GHf3uv6gZs2a5ffdd1+h1y5YsGBtu2dtVk9MRI5Rpvnzi1ASE5EaSmIikjR9OikiSVNPTESSpTExEUmekpiIJE1JTPqlnX8we/fuDcanTQsu+cfhw4eD8eHDh+fGhg4N//nF5vwK1YEBjBw5MjcWG7j+xje+EYx//etfD8Zjy9FNmTIlN/aHP7R/5UMlMRFJlu6dFJHkqScmIklTEhORpCmJiUjSlMREJFka2BeR5KknJskYNWpUMB6rd4rFDx06lBvbt29fcN/3338/GI/NdRb6hxibwy32c8XO29GjR4PxUE+no6MjuG8rpJTEwr8pwMweMbNdZrapattEM1tpZm9kXyc0t5ki0kq990/GHmUQTWLAo8Dx01DeAqxy95nAqux7ERkEiiawZJKYu78I7Dlu80JgafZ8KXB5g9slIm2UUhIb6JjYVHfvyp6/C0zNe6GZLQGWDPA4ItIGJ9Snk+7uoQVA3L0T6AQtFCKSgjL1soooMibWl24zmwaQfd3VuCaJSLuldDk50CS2HFicPV8MPNuY5ohIGaSUxKKXk2b2W+BiYLKZ7QB+AdwJLDOza4G3gEXNbORgV2/NUqgmKTYn16mnnhqMf/jhh3XFQ/OJxdaVDNWYAYwfPz4YD9WZxeq8TjrppGB8//79wfi4ceOC8Q0bNuTGYr+zuXPzl3ncvHlzcN+iypKgiogmMXe/Oid0SYPbIiIl0MjbjszsEeBfgF3u/oVs223AT4D3spfd6u4rstjPgWuBo8C/ufvzsWMM9HJSRAaxBl5OPkptnSnAve4+J3v0JrDZwFXA57N9/tPMhsQOoCQmIjUalcRy6kzzLASedPcP3f2vwFbgvNhOSmIiUqMfSWyyma2pehStCb3BzDZktzX23rY4HXi76jU7sm1BugFcRGr0Y2B/t7vnf9LQtweA2wHPvt4NXNPP9/g7JTEROUazyyfcvbv3uZk9CPwu+3YnUD2Fx2nZtiAlsRKI/cEMGRIe2wyVWHzve98L7nvKKacE4++9914wHloWDcK3r4wePTq4b2xKmliJRqi84+OPPw7uG1tOLvZzT5o0KRi///77c2Nz5swJ7htqW6xcp6hm3nZkZtOqblu8AuidIWc58ISZ3QOcCswEXo29n5KYiNRoVE8sp870YjObQ+VycjtwXXbM181sGbAZ6AGud/fwxGwoiYlIHxqVxHLqTB8OvP4O4I7+HENJTESOUaZbiopQEhORGkpiIpI0JTERSdoJNSmiiAwuGhOTfovVJMXqoUI2bdoUjMem0hk2bFgwXk8N25QpU4L7HjlyJBiPLekWavuIESOC+8Zq2Pbu3RuM79ixIxj//ve/nxv71a9+Fdz35ZdfDsYbQUlMRJKmJCYiSVMSE5FkNXJSxFZQEhORGuqJiUjSlMREJGlKYiKSNCWxJgnNlRSrV4otexabhyk0/1S9g6A9PT117R+yYsWKYPzgwYPB+OHDh4Px2NJmoX8MsbnKYr/TWK1XbM6wevaN/c5jbf/Sl76UG9u3b19w32ZTsauIJE+fTopI0tQTE5GkKYmJSLI0JiYiyVMSE5GkKYmJSNL06eQA1TM3VTNrrZrtoosuCsa/+93vBuMXXHBBbuzQoUPBfWNzcsXqwGJzoYV+Z7G2xf4eQutKQriOLNbTiLUtJnbeDhw4kBu78sorg/s+99xzA2pTUamNiYUrQAEze8TMdpnZpqptt5nZTjNbnz0ua24zRaSVehNZ7FEG0SQGPArM72P7ve4+J3uEy8JFJCkpJbHo5aS7v2hmM5rfFBEpi7IkqCKK9MTy3GBmG7LLzQl5LzKzJWa2xszW1HEsEWmR3kkRizzKYKBJ7AHgLGAO0AXcnfdCd+9097nuPneAxxKRFhtUl5N9cffu3udm9iDwu4a1SETariwJqogB9cTMbFrVt1cA4XXBRCQpg6onZma/BS4GJpvZDuAXwMVmNgdwYDtwXSMaE6opqtfEiROD8VNPPTUYnzlz5oD3jdX9zJo1KxiPrQ0ZmistVu80adKkYPydd94JxmNrQ4bqpWLrTsbW2xw1alQwvnr16tzYmDFjgvvGavdi40GxOcFC85Wdf/75wX1boSwJqogin05e3cfmh5vQFhEpgTL1soooVcW+iJRDWT55LEJJTERqpNQTq6dOTEQGqUYN7OfctjjRzFaa2RvZ1wnZdjOz+8xsa1aDem6RtiqJicgxiiawgr21R6m9bfEWYJW7zwRWZd8DLABmZo8lVOpRo5TERKRGo5KYu78I7Dlu80JgafZ8KXB51fbHvOJlYPxx5Vx9KtWYWOyj5dtvvz03dvLJJwf3HT9+fDAeK+8ITQvzt7/9LbhvbJqg/fv3B+OxUoPQcnOxJddCZQgAixYtCsbXrAnfTTZ27NjcWKx0ZMaMGcF4zBe/+MXcWKhdAG+//XYwHitdGTlyZDAeKvE4/fTTg/u2QpPHxKa6e1f2/F1gavZ8OlB94ndk27oIKFUSE5Fy6Menk5OPuy+60907i+7s7m5mdWVMJTEROUY/68R2D+C+6G4zm+buXdnl4q5s+06go+p1p2XbgjQmJiI1mnzb0XJgcfZ8MfBs1fYfZp9Sng/sq7rszKWemIjUaNSYWM5ti3cCy8zsWuAtoHfgdQVwGbAVOAT8qMgxlMREpEajkljObYsAl/TxWgeu7+8xlMRE5Bi9kyKmQklMRGqkdNtRy5NYqN7qvvvuC+47bVp+3VuszisWr2eJrtjyXLFjx2q5YsaNG5cbi9Uc3XnnncF4rG0//elPg/HQVD6xaXxWrVoVjG/bti0YD02fFJuCKFabN2zYsGA8ND0ShKfiee+994L7toKSmIgkTUlMRJKmJCYiydKkiCKSPH06KSJJU09MRJKmJCYiydKYWMCkSZP4zne+kxuP1TS9+eabubHYElyxeGxJt5BYzVCojgvic1fFlk0LLV3W3d2dGwNYunRpMH755ZcH488991wwHpoTLPY7+cpXvhKMz5s3LxgP1WrF6sCGDx8ejMdqA2NCtYOxv6eOjo7c2LvvvjvgNlVTEhORpGlgX0SSpctJEUmekpiIJE1JTESSpiQmIklTEhORZGlSxICenh527dqVG4/VS9WzhmHsvWM1S6G6oE9/+tPBfffsOX7t0GO99dZbwXisbaE5v2JzdsXWxHzmmWeC8Y0bNwbjoTqxWG1erJYrtt5naM6u2M8d+0ccq+WK7R9aKzRWgzZr1qzcWOycFJVSTyy62pGZdZjZC2a22cxeN7Mbs+0TzWylmb2RfZ3Q/OaKSCs0ebWjhiqyZFsPcLO7zwbOB643s9nALcAqd58JrMq+F5FBYFAlMXfvcvd12fP9wBYqS4svBHrvWVkKhO9PEZEkFE1gZUli/RoTM7MZwDnAK8DUqoUt3wWm5uyzBFgCMHLkyIG2U0RaqCwJqojCSczMxgBPATe5+wfVA5Pu7mbW50/t7p1AJ8D48ePTOTMiJ7CUPp0sMiaGmQ2jksAed/ens83dZjYti08D8j92FJGkDKrLSat0uR4Gtrj7PVWh5cBiKkuSLwaejb3XRx99xM6dO3PjsZOyY8eO3Njo0aOD+06ePDkYj300vXv37txYbImtoUPDpzk27Uvs4/wRI0bkxkJlKRBfWiz0cwN87nOfC8YPHjyYG4uVvezduzcYj523UNtD5RcQL8GI7R8bOjnllFNyY/v27QvuO2fOnNzYpk2bgvsWUaYEVUSRy8kLgB8AG81sfbbtVirJa5mZXQu8BSxqThNFpNUGVRJz95eAvMq8SxrbHBEpg0GVxETkxJPSwL6SmIgcYzCOiYnICUZJTESSpiQmIklTEstx+PBh1q9fnxt/+umnc2MA11xzTW4stqzZtm3bgvHYlDWh6XBidVyxmqHY1CtDhgwJxkPTEIWWBoP4H+uhQ4eC8a6urmA89P6xtsXq6+r5ndU7zU890wBBuA7tjDPOCO4bWoYvdtyilMREJFmNnhTRzLYD+4GjQI+7zzWzicB/ATOA7cAidw9XN+codNuRiJxYmnDb0Tx3n+Puc7PvGzaVl5KYiNRowb2TDZvKS0lMRGr0I4lNNrM1VY8lfb0d8EczW1sVLzSVVxEaExORY/Szl7W76hIxz4XuvtPMpgArzex/jzte7lReRagnJiI1Gnk56e47s6+7gGeA82jgVF5KYiJS45NPPin0iDGz0WY2tvc58G1gE/+YygsKTuWVe4xW1oPU02UEWLBgQW7sZz/7WXDfKVOmBOOxebNCdUGxeqdYnVesTixWLxV6/9DSYBCvB4rVwMXioZ8ttm+s7TGh/UO1VkXEfmexf+Ch+cQ2bNgQ3HfRovCsV+5e14kbNWqUn3322YVeu3HjxrWhy0kzO5NK7wsqw1dPuPsdZjYJWAZ8hmwqL3cPr22YQ2NiInKMRt4A7u7bgC/3sf19GjSVl5KYiNRQxb6IJE1JTESSpkkRRSRZmhRRRJKnJCYiSUspibW8Tiy0zmEzr8PnzZsXjP/yl78MxkN1ZuPGjQvuG1vbMVZHFqsTi9WphezaFS6Ujv19hNYRhfDv9MCBA8F9Y+clJtT22LxbsXnUYr/TlStXBuNbtmzJja1evTq4b0y9dWIjRozwjo6OQq/dunVrsE6sFdQTE5EaKfXElMRE5BiNnhSx2ZTERKSGemIikjQlMRFJmpKYiCRLxa4ikryUkli0TszMOoDHqMyB7UCnu//GzG4DfgK8l730VndfEXmvdM5MP3z2s58NxidPnhyMx9YwPO2004Lx7du358Zi9VBvvvlmMC7pqbdO7KSTTvKTTz650GvfeeedJOrEeoCb3X1dNkPjWjPrreS7191/3bzmiUg7pNQTiyaxbEWSruz5fjPbAkxvdsNEpD1SGxPr1xz7ZjYDOAd4Jdt0g5ltMLNHzGxCzj5LepdzqqulItIyLVh3smEKJzEzGwM8Bdzk7h8ADwBnAXOo9NTu7ms/d+9097ntvm4WkeJSSmKFPp00s2FUEtjj7v40gLt3V8UfBH7XlBaKSMuldNtRtCdmlSVjHga2uPs9VdunVb3sCirLMIlI4or2wsrSEytSYnEh8CdgI9Cbnm8FrqZyKenAduC6qmXJ896rHD+1yCBWb4nF0KFDPTa9VK89e/aUv8TC3V8C+jopwZowEUlXWXpZRahiX0RqKImJSNKUxEQkWZoUUUSSp56YiCRNSUxEkqYkJiLJKlMhaxFKYiJSQ0lMRJKmTydFJGnqiYlIslIbE+vXpIgicmJo5CwWZjbfzP5iZlvN7JZGt1VJTERqNCqJmdkQ4H5gATAbuNrMZjeyrbqcFJEaDRzYPw/Y6u7bAMzsSWAhsLlRB2h1EtsNvFX1/eRsWxmVtW1lbReobQPVyLad3oD3eJ5Km4oYcdz6GZ3u3ln1/XTg7arvdwD/VGf7jtHSJObuxyxmZ2Zr2j2hWp6ytq2s7QK1baDK1jZ3n9/uNvSHxsREpJl2Ah1V35+WbWsYJTERaabXgJlmdoaZnQRcBSxv5AHaPbDfGX9J25S1bWVtF6htA1XmttXF3XvM7AYq42xDgEfc/fVGHiO6UIiISJnpclJEkqYkJiJJa0sSa/ZtCPUws+1mttHM1h9X/9KOtjxiZrvMbFPVtolmttLM3si+TihR224zs53ZuVtvZpe1qW0dZvaCmW02s9fN7MZse1vPXaBdpThvqWr5mFh2G8L/AZdSKXx7Dbja3RtWwVsPM9sOzHX3thdGmtlFwAHgMXf/QrbtLmCPu9+Z/Qcwwd3/vSRtuw044O6/bnV7jmvbNGCau68zs7HAWuBy4F9p47kLtGsRJThvqWpHT+zvtyG4+0dA720Ichx3fxHYc9zmhcDS7PlSKv8IWi6nbaXg7l3uvi57vh/YQqVyvK3nLtAuqUM7klhftyGU6RfpwB/NbK2ZLWl3Y/ow1d27sufvAlPb2Zg+3GBmG7LLzbZc6lYzsxnAOcArlOjcHdcuKNl5S4kG9mtd6O7nUrnr/vrssqmUvDIWUKYamQeAs4A5QBdwdzsbY2ZjgKeAm9z9g+pYO89dH+0q1XlLTTuSWNNvQ6iHu+/Mvu4CnqFy+Vsm3dnYSu8Yy642t+fv3L3b3Y+6+yfAg7Tx3JnZMCqJ4nF3fzrb3PZz11e7ynTeUtSOJNb02xAGysxGZwOumNlo4NvApvBeLbccWJw9Xww828a2HKM3QWSuoE3nzswMeBjY4u73VIXaeu7y2lWW85aqtlTsZx8h/wf/uA3hjpY3og9mdiaV3hdUbsl6op1tM7PfAhdTmRalG/gF8N/AMuAzVKY1WuTuLR9gz2nbxVQuiRzYDlxXNQbVyrZdCPwJ2Aj0Tox1K5Xxp7adu0C7rqYE5y1Vuu1IRJKmgX0RSZqSmIgkTUlMRJKmJCYiSVMSE5GkKYmJSNKUxEQkaf8PVo2n+g0dlo4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDAY2krK065t"
      },
      "source": [
        "### c) Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0M8L-K065t"
      },
      "source": [
        "# use maximum normalization\n",
        "train_images = train_images / np.float32(255)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msQ_biny065u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "1f395d01-bbaf-4664-d3a2-3b7458121c99"
      },
      "source": [
        "train_images.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>pixel40</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192157</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.858824</td>\n",
              "      <td>0.847059</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>...</td>\n",
              "      <td>0.956863</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.952941</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.878431</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.545098</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.486275</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.298039</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086275</td>\n",
              "      <td>0.462745</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.831373</td>\n",
              "      <td>0.803922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.219608</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.031373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.686275</td>\n",
              "      <td>0.611765</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.760784</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.694118</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.686275</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.129412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.807843</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.949020</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.545098</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "1     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "2     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "3     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "4     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hvl4Hst065u"
      },
      "source": [
        "\n",
        "## 2. Model specific data preparation (tensorflow)\n",
        "## a) Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts0H5owM065v"
      },
      "source": [
        "\n",
        "x_train_pt = torch.from_numpy(train_images.values.reshape((-1, 1, 28, 28)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAjl91Lm065v"
      },
      "source": [
        "### b) Tensor view of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0SONiS065w",
        "outputId": "bda0091f-fc03-4921-feb5-f071701eabf2"
      },
      "source": [
        "x_train_pt.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d-1O3ac065w",
        "outputId": "810568d3-e6a8-44d9-e70e-d65ad89fdede"
      },
      "source": [
        "x_train_pt[0][0][5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000, 0.6902, 0.5255,\n",
              "        0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.0392,\n",
              "        0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUJVqsI065x"
      },
      "source": [
        "## 3. Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsQu8jb2065x"
      },
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if isinstance(m, nn.Linear):\n",
        "      nn.init.uniform_(m.weight.data, -1,1)\n",
        "      nn.init.zeros_(m.bias.data)\n",
        "  #if isinstance(m, nn.Conv2d):\n",
        "  #    nn.init.uniform_(m.weight.data, 0, 0.02)\n",
        "  #    nn.init.zeros_(m.bias.data)\n",
        "  #if isinstance(m, nn.ConvTranspose2d):\n",
        "  #    nn.init.uniform_(m.weight.data, 0, 0.02)\n",
        "  #    nn.init.zeros_(m.bias.data)\n",
        "  if classname.find('Conv') != -1:\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "      nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = args\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUFkLr4M065y"
      },
      "source": [
        "### a.1) Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ9ReExW065z"
      },
      "source": [
        "def generator_model():\n",
        "    model = nn.Sequential()\n",
        "    model.add_module(\"Conv2D1\", nn.ConvTranspose2d(100, 64, 7, stride=1, padding=0, bias=True))\n",
        "    #model.add_module(\"Batchnorm1\", nn.BatchNorm2d(64))\n",
        "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
        "    #model.add_module(\"Reshape\", Reshape(-1, 64, 7, 7))\n",
        "    \n",
        "    model.add_module(\"Conv2D2\", nn.ConvTranspose2d(64, 32, (8,8), stride=(1,1), padding=0, bias=True))\n",
        "    #model.add_module(\"Batchnorm2\", nn.BatchNorm2d(32))\n",
        "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D3\", nn.ConvTranspose2d(32, 1, (15,15), stride=1, padding=0, bias=True))\n",
        "    #model.add_module(\"Batchnorm3\", nn.BatchNorm2d(1))\n",
        "    model.add_module(\"Sigmoid1\", nn.Sigmoid())\n",
        "    return model\n",
        "generator = generator_model()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7tqK5yB0650"
      },
      "source": [
        "###  a.2) Inspect the generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoiTZ37X0650",
        "outputId": "4be7026d-2134-40d6-df81-1dd3932b8b5b"
      },
      "source": [
        "print(generator)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (Batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
            "  (Batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
            "  (Batchnorm3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Sigmoid1): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0v3fU5j0650",
        "outputId": "7734a700-5539-4290-c5fe-cdef10d233ae"
      },
      "source": [
        "generator.apply(weights_init)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
              "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
              "  (Sigmoid1): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZJiTRZ065z",
        "outputId": "1cfed101-3f1b-4fee-bb36-f7d3fb93623d"
      },
      "source": [
        "# generated image not trained\n",
        "fake_im_not_trained = generator(torch.normal(0, 1, size=[1, 100, 1, 1]))\n",
        "# check output shape of generator\n",
        "fake_im_not_trained"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.5092, 0.5096, 0.5083, 0.5084, 0.5091, 0.5132, 0.5096, 0.5134,\n",
              "           0.5132, 0.5132, 0.5181, 0.5088, 0.5086, 0.5116, 0.5161, 0.5161,\n",
              "           0.5111, 0.5117, 0.5111, 0.5132, 0.5106, 0.5094, 0.5084, 0.5092,\n",
              "           0.5113, 0.5105, 0.5099, 0.5099],\n",
              "          [0.5097, 0.5095, 0.5084, 0.5092, 0.5138, 0.5164, 0.5145, 0.5164,\n",
              "           0.5188, 0.5263, 0.5149, 0.5170, 0.5195, 0.5189, 0.5250, 0.5127,\n",
              "           0.5224, 0.5214, 0.5136, 0.5192, 0.5119, 0.5184, 0.5067, 0.5100,\n",
              "           0.5092, 0.5145, 0.5119, 0.5095],\n",
              "          [0.5099, 0.5107, 0.5096, 0.5116, 0.5169, 0.5178, 0.5261, 0.5248,\n",
              "           0.5183, 0.5257, 0.5142, 0.5256, 0.5128, 0.5183, 0.5288, 0.5253,\n",
              "           0.5188, 0.5193, 0.5113, 0.5165, 0.5181, 0.5181, 0.5154, 0.5101,\n",
              "           0.5101, 0.5131, 0.5111, 0.5108],\n",
              "          [0.5111, 0.5135, 0.5133, 0.5136, 0.5227, 0.5241, 0.5192, 0.5193,\n",
              "           0.5225, 0.5097, 0.5233, 0.5292, 0.5374, 0.5308, 0.5271, 0.5302,\n",
              "           0.5259, 0.5330, 0.5389, 0.5085, 0.5146, 0.5254, 0.5052, 0.5130,\n",
              "           0.5155, 0.5119, 0.5143, 0.5093],\n",
              "          [0.5101, 0.5147, 0.5116, 0.5211, 0.5210, 0.5207, 0.5208, 0.5293,\n",
              "           0.5251, 0.5266, 0.5155, 0.5141, 0.5228, 0.5280, 0.5316, 0.5390,\n",
              "           0.5290, 0.5390, 0.5285, 0.5167, 0.5205, 0.5104, 0.5141, 0.5099,\n",
              "           0.5146, 0.5119, 0.5052, 0.5090],\n",
              "          [0.5109, 0.5105, 0.5129, 0.5120, 0.5115, 0.5220, 0.5229, 0.5180,\n",
              "           0.5109, 0.5205, 0.5094, 0.5108, 0.5112, 0.5122, 0.5214, 0.5187,\n",
              "           0.5120, 0.5197, 0.5111, 0.5297, 0.5083, 0.5033, 0.5122, 0.5132,\n",
              "           0.5146, 0.5125, 0.5117, 0.5098],\n",
              "          [0.5076, 0.5116, 0.5207, 0.5228, 0.5193, 0.5271, 0.5204, 0.5239,\n",
              "           0.5323, 0.5397, 0.5165, 0.5356, 0.5090, 0.5472, 0.5206, 0.5160,\n",
              "           0.5216, 0.5226, 0.5153, 0.5404, 0.5171, 0.5205, 0.5063, 0.5094,\n",
              "           0.5155, 0.5136, 0.5106, 0.5083],\n",
              "          [0.5066, 0.5156, 0.5219, 0.5218, 0.5207, 0.5261, 0.5307, 0.5356,\n",
              "           0.5277, 0.5565, 0.5349, 0.5084, 0.5062, 0.5157, 0.5146, 0.5032,\n",
              "           0.5102, 0.5449, 0.5242, 0.5282, 0.5241, 0.4983, 0.5238, 0.5153,\n",
              "           0.5233, 0.5120, 0.5090, 0.5089],\n",
              "          [0.5130, 0.5119, 0.5239, 0.5134, 0.5187, 0.5084, 0.5251, 0.5066,\n",
              "           0.5242, 0.5447, 0.5358, 0.5211, 0.4969, 0.5366, 0.5191, 0.5311,\n",
              "           0.5176, 0.5185, 0.5340, 0.5221, 0.5047, 0.5287, 0.5051, 0.5107,\n",
              "           0.5094, 0.5152, 0.5077, 0.5121],\n",
              "          [0.5095, 0.5099, 0.5119, 0.5163, 0.5238, 0.4918, 0.5238, 0.5292,\n",
              "           0.5184, 0.5409, 0.5360, 0.5374, 0.5101, 0.5092, 0.5379, 0.5601,\n",
              "           0.5543, 0.5260, 0.5255, 0.5526, 0.5375, 0.5081, 0.5099, 0.5199,\n",
              "           0.5098, 0.5053, 0.5057, 0.5064],\n",
              "          [0.5072, 0.5149, 0.5209, 0.5137, 0.5100, 0.5207, 0.5336, 0.5343,\n",
              "           0.5059, 0.5302, 0.5225, 0.5422, 0.5266, 0.5070, 0.5031, 0.5043,\n",
              "           0.5013, 0.5043, 0.5110, 0.5402, 0.5060, 0.5424, 0.5041, 0.5063,\n",
              "           0.5093, 0.5262, 0.5108, 0.5057],\n",
              "          [0.5088, 0.5110, 0.5209, 0.5064, 0.5305, 0.5247, 0.5059, 0.5070,\n",
              "           0.5142, 0.5106, 0.5203, 0.5247, 0.5216, 0.5287, 0.5149, 0.4930,\n",
              "           0.4859, 0.4875, 0.5090, 0.5285, 0.5072, 0.5085, 0.5055, 0.5295,\n",
              "           0.5274, 0.5105, 0.5047, 0.5032],\n",
              "          [0.5112, 0.5126, 0.5220, 0.5100, 0.5162, 0.5177, 0.5320, 0.5031,\n",
              "           0.5180, 0.5346, 0.5307, 0.5389, 0.5109, 0.5116, 0.5197, 0.5160,\n",
              "           0.5299, 0.4712, 0.5221, 0.5167, 0.4841, 0.5045, 0.5057, 0.5012,\n",
              "           0.4952, 0.5110, 0.5062, 0.5056],\n",
              "          [0.5102, 0.5154, 0.5156, 0.5284, 0.5020, 0.5139, 0.5114, 0.5096,\n",
              "           0.5013, 0.5378, 0.4821, 0.5303, 0.4949, 0.4983, 0.5186, 0.4945,\n",
              "           0.4792, 0.5174, 0.5183, 0.4644, 0.5386, 0.4810, 0.5090, 0.5132,\n",
              "           0.5075, 0.5074, 0.4987, 0.5042],\n",
              "          [0.5105, 0.5074, 0.5073, 0.5028, 0.5191, 0.5107, 0.4993, 0.4987,\n",
              "           0.5080, 0.4974, 0.5123, 0.5163, 0.5041, 0.5047, 0.5058, 0.4986,\n",
              "           0.4914, 0.4926, 0.4914, 0.5081, 0.5051, 0.4979, 0.4908, 0.5027,\n",
              "           0.5144, 0.5104, 0.4995, 0.5114],\n",
              "          [0.5109, 0.5074, 0.5103, 0.5150, 0.5072, 0.5047, 0.5102, 0.4865,\n",
              "           0.5099, 0.4699, 0.4698, 0.4832, 0.4895, 0.5237, 0.5333, 0.5154,\n",
              "           0.4938, 0.5163, 0.4980, 0.4985, 0.4998, 0.5051, 0.5035, 0.5016,\n",
              "           0.5004, 0.5045, 0.5052, 0.5080],\n",
              "          [0.5072, 0.5078, 0.5159, 0.5036, 0.4951, 0.5215, 0.5102, 0.5038,\n",
              "           0.5005, 0.4540, 0.4915, 0.5027, 0.4774, 0.5305, 0.4891, 0.4924,\n",
              "           0.5361, 0.5126, 0.5157, 0.5121, 0.4959, 0.5143, 0.5112, 0.5033,\n",
              "           0.5087, 0.5119, 0.5106, 0.5098],\n",
              "          [0.5155, 0.5094, 0.5013, 0.5028, 0.4963, 0.4955, 0.5106, 0.4730,\n",
              "           0.4780, 0.4956, 0.4787, 0.5045, 0.4676, 0.5020, 0.5233, 0.5124,\n",
              "           0.4762, 0.5020, 0.5067, 0.4780, 0.5044, 0.4894, 0.4981, 0.5023,\n",
              "           0.5185, 0.5014, 0.5014, 0.5055],\n",
              "          [0.5122, 0.5098, 0.5077, 0.5119, 0.5097, 0.4931, 0.5118, 0.4915,\n",
              "           0.4875, 0.4957, 0.5086, 0.4730, 0.4688, 0.5008, 0.5207, 0.5284,\n",
              "           0.5079, 0.5111, 0.5162, 0.5069, 0.4968, 0.4899, 0.4958, 0.5247,\n",
              "           0.5242, 0.4945, 0.4962, 0.5062],\n",
              "          [0.5113, 0.5138, 0.5206, 0.5185, 0.5052, 0.5073, 0.4931, 0.5130,\n",
              "           0.5065, 0.4882, 0.4885, 0.4944, 0.5018, 0.5135, 0.5145, 0.5167,\n",
              "           0.5085, 0.5265, 0.5299, 0.5163, 0.5160, 0.5130, 0.5249, 0.5074,\n",
              "           0.5173, 0.5039, 0.5044, 0.5092],\n",
              "          [0.5090, 0.5064, 0.4955, 0.5163, 0.5052, 0.4967, 0.5089, 0.4783,\n",
              "           0.5023, 0.4742, 0.4827, 0.4957, 0.4795, 0.5085, 0.5004, 0.5038,\n",
              "           0.4978, 0.5114, 0.5136, 0.5038, 0.5252, 0.5171, 0.5155, 0.5074,\n",
              "           0.5065, 0.5017, 0.5090, 0.5021],\n",
              "          [0.5113, 0.5049, 0.5033, 0.5055, 0.4979, 0.5105, 0.5001, 0.4869,\n",
              "           0.5201, 0.4890, 0.5056, 0.4904, 0.5073, 0.5378, 0.4983, 0.5141,\n",
              "           0.5528, 0.5277, 0.5165, 0.5227, 0.5032, 0.4993, 0.5297, 0.5010,\n",
              "           0.5073, 0.5105, 0.5009, 0.5066],\n",
              "          [0.5071, 0.5037, 0.5080, 0.4996, 0.4998, 0.5066, 0.5085, 0.5043,\n",
              "           0.5213, 0.5141, 0.5205, 0.5127, 0.4895, 0.5078, 0.5124, 0.5133,\n",
              "           0.5277, 0.5282, 0.5150, 0.5249, 0.5196, 0.5075, 0.5103, 0.5092,\n",
              "           0.5081, 0.5020, 0.5006, 0.5076],\n",
              "          [0.5109, 0.5026, 0.5009, 0.5062, 0.4987, 0.5007, 0.5067, 0.5034,\n",
              "           0.5040, 0.5054, 0.5067, 0.4995, 0.5046, 0.5052, 0.5239, 0.5042,\n",
              "           0.5214, 0.5182, 0.5034, 0.4917, 0.5161, 0.5100, 0.5113, 0.4992,\n",
              "           0.5047, 0.4980, 0.5010, 0.5079],\n",
              "          [0.5126, 0.5118, 0.5066, 0.5044, 0.5062, 0.5056, 0.4958, 0.5089,\n",
              "           0.4989, 0.5050, 0.5011, 0.5040, 0.5087, 0.5126, 0.5041, 0.5042,\n",
              "           0.5039, 0.5125, 0.5221, 0.5198, 0.5058, 0.5119, 0.5124, 0.5129,\n",
              "           0.5102, 0.5047, 0.5054, 0.5101],\n",
              "          [0.5107, 0.5069, 0.5100, 0.5089, 0.5067, 0.5101, 0.5001, 0.5097,\n",
              "           0.5102, 0.5066, 0.4998, 0.5059, 0.5132, 0.4915, 0.5147, 0.5146,\n",
              "           0.5075, 0.5212, 0.5105, 0.5137, 0.5157, 0.5125, 0.5126, 0.5089,\n",
              "           0.5074, 0.5086, 0.5090, 0.5094],\n",
              "          [0.5107, 0.5073, 0.5105, 0.5084, 0.5092, 0.5052, 0.5100, 0.5075,\n",
              "           0.5081, 0.5097, 0.5098, 0.5147, 0.5110, 0.5045, 0.5125, 0.5067,\n",
              "           0.5072, 0.5075, 0.5085, 0.5125, 0.5106, 0.5105, 0.5148, 0.5119,\n",
              "           0.5110, 0.5091, 0.5107, 0.5100],\n",
              "          [0.5100, 0.5088, 0.5074, 0.5075, 0.5074, 0.5090, 0.5073, 0.5066,\n",
              "           0.5088, 0.5082, 0.5049, 0.5122, 0.5019, 0.5110, 0.5091, 0.5067,\n",
              "           0.5118, 0.5104, 0.5100, 0.5053, 0.5115, 0.5047, 0.5070, 0.5101,\n",
              "           0.5109, 0.5095, 0.5101, 0.5096]]]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfrxvvCj0651"
      },
      "source": [
        "### a.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yKD8kav0651",
        "outputId": "de10ef71-943d-4959-dbae-c406284fad3c"
      },
      "source": [
        "generator[0].weight[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7009, -0.7041, -0.1102,  ..., -0.9771, -0.4857, -0.3781],\n",
              "         [-0.6143,  0.4888,  0.6448,  ...,  0.0832,  0.8357,  0.6795],\n",
              "         [ 0.4979, -0.8874, -0.8001,  ...,  0.9009,  0.9691,  0.3165],\n",
              "         ...,\n",
              "         [-0.6585, -0.0224, -0.1519,  ...,  0.1275, -0.2774, -0.0516],\n",
              "         [-0.7280,  0.9821,  0.4851,  ..., -0.3166, -0.4248,  0.9474],\n",
              "         [ 0.1445,  0.7119,  0.0860,  ...,  0.5282, -0.0927, -0.8238]],\n",
              "\n",
              "        [[ 0.4253, -0.2040,  0.6886,  ...,  0.2422, -0.3324, -0.0418],\n",
              "         [-0.3385,  0.2522, -0.0556,  ..., -0.6397, -0.4418, -0.7989],\n",
              "         [-0.6277,  0.1049, -0.9963,  ..., -0.5462, -0.1564,  0.2832],\n",
              "         ...,\n",
              "         [-0.1146,  0.5828,  0.7325,  ...,  0.8839, -0.8728,  0.2547],\n",
              "         [ 0.5764,  0.2741, -0.6448,  ...,  0.7589,  0.4808,  0.8759],\n",
              "         [-0.2187, -0.5066,  0.6027,  ..., -0.5648, -0.2003, -0.3458]],\n",
              "\n",
              "        [[ 0.7184, -0.5869,  0.6189,  ...,  0.3086,  0.9629,  0.1802],\n",
              "         [ 0.1734, -0.7408, -0.1413,  ...,  0.3486, -0.8530, -0.6471],\n",
              "         [-0.4245,  0.5896, -0.7446,  ..., -0.8822,  0.6812,  0.6976],\n",
              "         ...,\n",
              "         [-0.1115, -0.4258, -0.5078,  ..., -0.3168, -0.6223,  0.0978],\n",
              "         [ 0.4185,  0.8263,  0.3216,  ..., -0.7762, -0.5386,  0.5938],\n",
              "         [ 0.3414,  0.9750, -0.1726,  ...,  0.6391, -0.7604, -0.1137]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.8332, -0.4268, -0.8425,  ..., -0.1155,  0.7642, -0.9478],\n",
              "         [ 0.5639, -0.8045,  0.8532,  ...,  0.4168,  0.2630, -0.8181],\n",
              "         [ 0.7156, -0.6815, -0.3449,  ...,  0.8440, -0.0498, -0.9073],\n",
              "         ...,\n",
              "         [-0.9914, -0.2064,  0.3017,  ..., -0.6908,  0.9319,  0.8113],\n",
              "         [ 0.6252, -0.8384,  0.9173,  ..., -0.3392,  0.6846,  0.2398],\n",
              "         [-0.1296,  0.1185,  0.0990,  ..., -0.0365,  0.3033,  0.1741]],\n",
              "\n",
              "        [[-0.7637, -0.9078,  0.5262,  ..., -0.1726,  0.8746, -0.1886],\n",
              "         [ 0.7550,  0.8817, -0.4579,  ..., -0.9670, -0.4248, -0.5509],\n",
              "         [-0.6140,  0.3370, -0.9383,  ..., -0.7606,  0.2684,  0.8928],\n",
              "         ...,\n",
              "         [ 0.2516, -0.9037, -0.6914,  ..., -0.0390,  0.0289, -0.2435],\n",
              "         [-0.2047,  0.1202, -0.2468,  ..., -0.3162, -0.3699, -0.9717],\n",
              "         [ 0.2836,  0.0159, -0.6063,  ..., -0.4091, -0.0184, -0.5587]],\n",
              "\n",
              "        [[ 0.3125,  0.4626,  0.2827,  ...,  0.3868,  0.9292,  0.8500],\n",
              "         [-0.5973, -0.6990,  0.1300,  ...,  0.9795,  0.6381, -0.9539],\n",
              "         [-0.3205, -0.6873, -0.3170,  ..., -0.3834, -0.8405, -0.4467],\n",
              "         ...,\n",
              "         [-0.1893,  0.5314, -0.3950,  ...,  0.4558,  0.0700, -0.3673],\n",
              "         [-0.1879, -0.1975, -0.8147,  ..., -0.9842,  0.2045,  0.0512],\n",
              "         [-0.8167, -0.8222,  0.2763,  ..., -0.5280, -0.4799,  0.6712]]],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "Sln7_yqA0651",
        "outputId": "6495efe2-b6aa-43ea-c32a-0a4f8c7bb1ff"
      },
      "source": [
        "generator[0].weight.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4b543b6c5ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Reshape' object has no attribute 'weight'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMFFTGQ0651"
      },
      "source": [
        "generator[0].bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxJ6gVze0653"
      },
      "source": [
        "generator[0].bias.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohr9EW-y0654"
      },
      "source": [
        "### b.1) Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGDLcmK00654"
      },
      "source": [
        "def discriminator_model():\n",
        "    model = nn.Sequential()\n",
        "    model.add_module(\"Conv2D1\", nn.Conv2d(1, 2, kernel_size=5, stride=1, padding=2))\n",
        "    model.add_module(\"Pooling1\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
        "    model.add_module(\"Dropout1\", nn.Dropout(0.3))\n",
        "    \n",
        "    model.add_module(\"Conv2D2\", nn.Conv2d(2, 2, kernel_size=5, stride=1, padding=2))\n",
        "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D3\", nn.Conv2d(2, 1, kernel_size=5, stride=1, padding=0))\n",
        "    model.add_module(\"LeakyRelu3\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Flatten1\", nn.Flatten())\n",
        "    \n",
        "    model.add_module(\"Dense1\", nn.Linear(100,100))\n",
        "    model.add_module(\"LeakyRelu4\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Dense2\", nn.Linear(100,64))\n",
        "    model.add_module(\"Tanh\", nn.Tanh())\n",
        "    \n",
        "    model.add_module(\"Dense3\", nn.Linear(64,1))\n",
        "    model.add_module(\"Sigmoid\", nn.Sigmoid())\n",
        "    return model\n",
        "discriminator = discriminator_model()"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eGFfyYO0655"
      },
      "source": [
        "### b.2) Inspect the discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqwNgL5J0655",
        "scrolled": false,
        "outputId": "500951ca-3b44-4979-c75e-22799382d803"
      },
      "source": [
        "print(discriminator)\n",
        "discriminator(fake_im_not_trained)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
            "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
            "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
            "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
            "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (Tanh): Tanh()\n",
            "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (Sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4946]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTX4zp9c0655",
        "outputId": "0872c840-739b-4da5-dbe5-c2eee65f6a74"
      },
      "source": [
        "discriminator.apply(weights_init)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
              "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
              "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
              "  (Tanh): Tanh()\n",
              "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (Sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U8TOF5r0655"
      },
      "source": [
        "### b.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yXCZgM80656"
      },
      "source": [
        "discriminator[0].weight[0].type()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCKCE5rX0656"
      },
      "source": [
        "discriminator[0].weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u4FdvnE0657"
      },
      "source": [
        "discriminator[0].bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFVYDoT0657"
      },
      "source": [
        "discriminator[0].bias.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Itee_8M0657"
      },
      "source": [
        "## 4. Loss & Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQrC1KNF0658"
      },
      "source": [
        "### 4.a) Generator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJbFTAz0658"
      },
      "source": [
        "cross_entropy = nn.BCEWithLogitsLoss()\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(torch.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzHIkuZM0658"
      },
      "source": [
        "### 4.b) Discriminator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDIX2a000659"
      },
      "source": [
        "def real_discriminator_loss(real_output):\n",
        "    return  cross_entropy(torch.ones_like(real_output), real_output)\n",
        "\n",
        "def fake_discriminator_loss(fake_output):\n",
        "    return cross_entropy(torch.zeros_like(fake_output), fake_output)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7hrseRk0659"
      },
      "source": [
        "## 4.c) Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hic_TlMX0659"
      },
      "source": [
        "generator_optimizer = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-3)\n",
        "\n",
        "def correct_classification(y_true, y_prob):\n",
        "    assert y_true.size() == y_prob.size()\n",
        "    y_prob = (y_prob > 0.5).float()\n",
        "    return (y_true == y_prob).sum().item()"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYLo8yIj0659"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs8u8LUz065-"
      },
      "source": [
        "# This annotation causes the function to be \"compiled\".\n",
        "#@tf.function\n",
        "def train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size = 100):\n",
        "    gen_loss_tot = []\n",
        "    disc_loss_tot = []\n",
        "    disc_acc_real_tot = 0\n",
        "    disc_acc_fake_tot = 0\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    for beg_i in range(0, x_train_pt.shape[0], batch_size):\n",
        "        x_train_batch_pt = x_train_pt[beg_i:beg_i + batch_size]\n",
        "\n",
        "        x_fake_batch_pt = torch.normal(0, 1, size=[batch_size, 100, 1, 1])\n",
        "        \n",
        "        discriminator_optimizer.zero_grad()\n",
        "        real_output = discriminator(x_train_batch_pt.float()).view(-1)\n",
        "        #disc_loss_real = cross_entropy(torch.full((batch_size,), 1, dtype=torch.float), real_output)\n",
        "        disc_loss_real = real_discriminator_loss(real_output)\n",
        "        disc_loss_real.backward()\n",
        "        \n",
        "        generated_images = generator(x_fake_batch_pt)\n",
        "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
        "        #disc_loss_fake = cross_entropy(torch.full((batch_size,), 0, dtype=torch.float), fake_output)\n",
        "        disc_loss_fake = fake_discriminator_loss(fake_output)\n",
        "        disc_loss_fake.backward()\n",
        "        err = disc_loss_fake + disc_loss_real\n",
        "        discriminator_optimizer.step()\n",
        "        \n",
        "        # optimize generator\n",
        "        generator_optimizer.zero_grad()\n",
        "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
        "        #gen_loss= cross_entropy(torch.full((batch_size,), 1, dtype=torch.float), fake_output)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        gen_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "        \n",
        "        gen_loss_tot.append(gen_loss.mean().item())\n",
        "        disc_loss_tot.append(err.mean().item())\n",
        "        disc_acc_real_tot += correct_classification(torch.ones_like(real_output), real_output)\n",
        "        disc_acc_fake_tot += correct_classification(torch.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    disc_acc_real_tot = disc_acc_real_tot/x_train_pt.size(0)\n",
        "    disc_acc_fake_tot = disc_acc_fake_tot/x_train_pt.size(0)\n",
        "    print([disc_acc_real_tot, disc_acc_fake_tot])\n",
        "    disc_acc_tot = np.mean([disc_acc_real_tot, disc_acc_fake_tot])\n",
        "    return gen_loss_tot, disc_loss_tot, disc_acc_tot"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "F-ILomMn065-",
        "scrolled": true,
        "outputId": "bea7b305-3f62-4998-b881-18859362645e"
      },
      "source": [
        "train_losses_generator_pt = []\n",
        "train_losses_discriminator_pt = []\n",
        "train_acc_discriminator_pt = []\n",
        "epochs = 15\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    gen_loss, disc_loss, disc_acc = train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
        "    gen_loss = np.mean(gen_loss)\n",
        "    disc_loss = np.mean(disc_loss)\n",
        "    train_losses_generator_pt.append(gen_loss)\n",
        "    train_losses_discriminator_pt.append(disc_loss)\n",
        "    train_acc_discriminator_pt.append(disc_acc*100)\n",
        "\n",
        "\n",
        "    template = (\"Epoch {}, Loss_Generator: {}, Loss_Discriminator: {}, Discriminator_Accuracy: {}\")\n",
        "    print(template.format(epoch+1, gen_loss, disc_loss, disc_acc*100))\n",
        "end = time.time()\n",
        "print(f\"Total training time{(end - start)/60.0}\")"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 0.0]\n",
            "Epoch 1, Loss_Generator: 0.3141033135354519, Loss_Discriminator: 1.0080019915103913, Discriminator_Accuracy: 50.0\n",
            "[1.0, 0.0]\n",
            "Epoch 2, Loss_Generator: 0.313262993345658, Loss_Discriminator: 1.0064100432395935, Discriminator_Accuracy: 50.0\n",
            "[1.0, 0.0]\n",
            "Epoch 3, Loss_Generator: 0.31326237464944523, Loss_Discriminator: 1.0064094837506612, Discriminator_Accuracy: 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-018828624942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-129-f8678fef50bd>\u001b[0m in \u001b[0;36mtrain_step_pt\u001b[0;34m(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdisc_loss_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake_batch_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#disc_loss_fake = cross_entropy(torch.full((batch_size,), 0, dtype=torch.float), fake_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    840\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    841\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGOH030LKOwE"
      },
      "source": [
        "print(f\"Total training time{(end - start)/60.0}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Mbb_M065-"
      },
      "source": [
        "### b) Training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8-7QBvL065_"
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(train_acc_discriminator_pt)\n",
        "plt.title('discriminator accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['discriminator_train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8W0zvk065_"
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(train_losses_generator_pt)\n",
        "plt.plot(train_losses_discriminator_pt)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['generator', 'discriminator'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UiwHcmI4C_d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVnypYA065_"
      },
      "source": [
        "### c1) Generator output before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMDDynAD066A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "184c8b9a-16a6-48be-90ab-4c2e431d42ec"
      },
      "source": [
        "\n",
        "fake_im_not_trained = fake_im_not_trained.detach().numpy() * 255\n",
        "fake_im_not_trained = fake_im_not_trained.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im_not_trained, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3KjkI-066A"
      },
      "source": [
        "### c2) Generator output after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfqPBgZo066A"
      },
      "source": [
        "seed2 = torch.normal(0, 1, size=[1, 100, 1, 1])\n",
        "generator.train(False)\n",
        "fake_im = generator(seed2)\n",
        "fake_im = fake_im.detach().numpy() * 255\n",
        "fake_im = fake_im.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDy-AvTmL6D4"
      },
      "source": [
        "## 6. References\n",
        "The presented model is based on a combination of two tutorials for deep cnn-gans:\n",
        "1) https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n",
        "2) https://www.tensorflow.org/tutorials/generative/dcgan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_UcuzDvL6D4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}