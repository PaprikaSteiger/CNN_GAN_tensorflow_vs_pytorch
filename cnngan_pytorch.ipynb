{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Kopie von cnngan_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QAjl91Lm065v",
        "UUFkLr4M065y",
        "I7tqK5yB0650",
        "zfrxvvCj0651",
        "ohr9EW-y0654",
        "-eGFfyYO0655",
        "8U8TOF5r0655",
        "sQrC1KNF0658",
        "E88Mbb_M065-",
        "rdVnypYA065_",
        "RH3KjkI-066A"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/blob/master/cnngan_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVotrWM-065f"
      },
      "source": [
        "# Implementing a CNNGAN with pytroch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt9oTYk6065n"
      },
      "source": [
        "## 1. Import and Preprocessing\n",
        "### a) Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOvHT87j065o"
      },
      "source": [
        "# Load required packages - data handling & plotting\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load required packages - deep learning \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2kizsA7065p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad2b855-db7b-4d73-b849-0cebcb3350bb"
      },
      "source": [
        "print(f\"tensorflow: {torch.__version__}\")\n",
        "import sys\n",
        "print(f\"python: {sys.version[:5]}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow: 1.8.1+cu101\n",
            "python: 3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7um10LNJ065q"
      },
      "source": [
        "### b) Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9K_QRXq065r"
      },
      "source": [
        "#download and save to file\n",
        "#urllib.request.urlretrieve(\n",
        "#    \"https://media.githubusercontent.com/media/mmeierer/CNN---TensorFlow-vs-PyTorch/main/fashion-mnist_train.csv\",\n",
        "#    \"fashion-mnist_train2.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOi4NVI065r"
      },
      "source": [
        "train_data = pd.read_csv('https://media.githubusercontent.com/media/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/master/fashion-mnist_train.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukf4AIqY065r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "2a79e83f-53dc-40e7-8c73-31714894b423"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>211</td>\n",
              "      <td>220</td>\n",
              "      <td>214</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>222</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>214</td>\n",
              "      <td>163</td>\n",
              "      <td>146</td>\n",
              "      <td>165</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>183</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>102</td>\n",
              "      <td>165</td>\n",
              "      <td>160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>163</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>249</td>\n",
              "      <td>207</td>\n",
              "      <td>197</td>\n",
              "      <td>202</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>69</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>136</td>\n",
              "      <td>147</td>\n",
              "      <td>144</td>\n",
              "      <td>121</td>\n",
              "      <td>102</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "2      6       0       0       0  ...         0         0         0         0\n",
              "3      0       0       0       0  ...         0         0         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqXVdux_065s"
      },
      "source": [
        "train_images = train_data.iloc[:,1:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54zxTjsL065s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "366987d5-c846-43b7-8762-3c8de41d837d"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images.values[0].reshape(28,28), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDAY2krK065t"
      },
      "source": [
        "### c) Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0M8L-K065t"
      },
      "source": [
        "# use maximum normalization\n",
        "train_images = train_images / np.float32(255)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msQ_biny065u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "3e7ceff7-7516-43a9-cc2f-165fe4551784"
      },
      "source": [
        "train_images.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>pixel40</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.360784</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.419608</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.890196</td>\n",
              "      <td>...</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.862745</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.749020</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.976471</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.772549</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086275</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180392</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.929412</td>\n",
              "      <td>0.898039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.454902</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3    pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "1     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "2     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "3     0.0     0.0     0.0  0.003922  ...       0.0       0.0       0.0       0.0\n",
              "4     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hvl4Hst065u"
      },
      "source": [
        "\n",
        "## 2. Model specific data preparation (tensorflow)\n",
        "## a) Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts0H5owM065v"
      },
      "source": [
        "x_train_pt = torch.from_numpy(train_images.values.reshape((-1, 1, 28, 28)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfpc1P3A065v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "174a8b77-3690-4341-e784-ac97c3ec0dde"
      },
      "source": [
        "# use random seed to create fake input data\n",
        "seed = torch.rand((28,28))\n",
        "seed_im = seed.numpy() * 255\n",
        "plt.figure()\n",
        "plt.imshow(seed_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAjl91Lm065v"
      },
      "source": [
        "### b) Tensor view of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR0SONiS065w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92a7b76-b999-4167-828c-9db30a689edc"
      },
      "source": [
        "x_train_pt.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx2B52_n065w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ddd3ca-4689-4675-fb37-8a12f04538a4"
      },
      "source": [
        "seed.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d-1O3ac065w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e08461d-92cb-4c03-fb01-c996b96b8fe8"
      },
      "source": [
        "x_train_pt[0][0][5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.9882, 0.9176, 0.9333,\n",
              "        0.8784, 0.8431, 0.8431, 0.8980, 0.4235, 0.7059, 0.8118, 0.8392, 0.8784,\n",
              "        0.9059, 0.9765, 0.9961, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUJVqsI065x"
      },
      "source": [
        "## 3. Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsQu8jb2065x"
      },
      "source": [
        "def weights_init(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "      nn.init.uniform_(m.weight.data, -1,1)\n",
        "      nn.init.zeros_(m.bias.data)\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "      nn.init.zeros_(m.bias.data)\n",
        "  if isinstance(m, nn.ConvTranspose2d):\n",
        "      nn.init.zeros_(m.bias.data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4KeOa9K065y"
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, channels, height, width):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = (channels, height, width)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUFkLr4M065y"
      },
      "source": [
        "### a.1) Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ9ReExW065z"
      },
      "source": [
        "def generator_model():\n",
        "    model = nn.Sequential()\n",
        "    model.add_module(\"Conv2D1\", nn.ConvTranspose2d(100, 64, 7, stride=1, padding=0, bias=True))\n",
        "    #model.add_module(\"Reshape\", Reshape(64, 7, 7))\n",
        "    model.add_module(\"Batchnorm1\", nn.BatchNorm2d(64))\n",
        "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D2\", nn.ConvTranspose2d(64, 32, (8,8), stride=(1,1), padding=0, bias=True))\n",
        "    model.add_module(\"Batchnorm2\", nn.BatchNorm2d(32))\n",
        "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D3\", nn.ConvTranspose2d(32, 1, (15,15), stride=1, padding=0, bias=True))\n",
        "    model.add_module(\"Batchnorm3\", nn.BatchNorm2d(1))\n",
        "    model.add_module(\"Sigmoid1\", nn.Sigmoid())\n",
        "    return model\n",
        "generator = generator_model()\n",
        "#generator.eval()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBZJiTRZ065z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea0a6c0-821d-4d80-ecde-1e2505a16339"
      },
      "source": [
        "# generated image not trained\n",
        "fake_im_not_trained = generator(torch.rand([1, 100, 1, 1]))\n",
        "# check output shape of generator\n",
        "fake_im_not_trained.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7tqK5yB0650"
      },
      "source": [
        "###  a.2) Inspect the generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoiTZ37X0650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a10e44-d205-45a9-b721-5cc77d85df98"
      },
      "source": [
        "print(generator)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
            "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
            "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Sigmoid1): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0v3fU5j0650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9037bc-00f5-4606-937f-197eeea4b3e0"
      },
      "source": [
        "generator.apply(weights_init)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
              "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
              "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (Sigmoid1): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfrxvvCj0651"
      },
      "source": [
        "### a.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yKD8kav0651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5562461-ef52-4f5b-f956-7a8e59bdd89e"
      },
      "source": [
        "generator[0].weight[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.8887e-03,  3.0843e-03, -1.5766e-02,  ..., -1.5429e-02,\n",
              "           2.2041e-05, -1.2728e-02],\n",
              "         [-1.3659e-02, -1.0908e-02,  1.0692e-02,  ..., -1.5092e-03,\n",
              "          -1.2230e-02, -1.6438e-02],\n",
              "         [ 6.6543e-03,  1.1022e-03,  1.0358e-02,  ...,  4.9830e-03,\n",
              "           1.5067e-02, -1.4729e-02],\n",
              "         ...,\n",
              "         [-9.3979e-03, -1.7596e-02,  3.7607e-03,  ..., -5.5988e-03,\n",
              "          -4.7987e-03,  1.4807e-02],\n",
              "         [-1.5566e-02, -7.0398e-03,  1.0977e-02,  ...,  5.0354e-03,\n",
              "          -1.7141e-03,  1.2319e-02],\n",
              "         [-1.5168e-02, -7.2223e-03, -1.5436e-02,  ..., -2.8202e-03,\n",
              "          -1.5201e-03,  1.5687e-02]],\n",
              "\n",
              "        [[ 1.3100e-02, -5.0210e-03, -9.6128e-03,  ...,  4.6047e-03,\n",
              "          -2.4638e-03, -1.6006e-02],\n",
              "         [-1.5325e-02, -1.1302e-02,  6.3962e-03,  ...,  4.4586e-03,\n",
              "           9.3401e-03,  4.7226e-04],\n",
              "         [-1.5836e-03, -1.6454e-02,  1.3041e-02,  ...,  1.0478e-02,\n",
              "          -1.2306e-02, -5.1995e-03],\n",
              "         ...,\n",
              "         [-9.0524e-03, -9.2798e-03,  1.0779e-02,  ...,  7.4929e-03,\n",
              "           9.0064e-03,  1.5283e-02],\n",
              "         [ 4.1104e-03, -1.4425e-02, -1.0950e-03,  ...,  1.4851e-02,\n",
              "          -1.1248e-03,  3.8554e-04],\n",
              "         [-1.2467e-03, -2.3915e-03, -1.7778e-02,  ..., -1.3999e-02,\n",
              "           8.2577e-03, -3.9722e-03]],\n",
              "\n",
              "        [[-2.0706e-03,  1.1617e-02, -1.1434e-03,  ...,  8.6410e-03,\n",
              "           8.0202e-03,  1.6209e-02],\n",
              "         [ 5.7757e-03,  1.6020e-02, -1.5612e-02,  ..., -1.5013e-02,\n",
              "           1.5514e-02, -1.5994e-03],\n",
              "         [ 1.1539e-02,  1.7703e-02, -1.0494e-02,  ..., -1.7804e-02,\n",
              "          -1.2407e-02, -1.5014e-02],\n",
              "         ...,\n",
              "         [ 1.3050e-02,  1.4513e-02,  7.3958e-03,  ...,  6.7230e-03,\n",
              "           2.7708e-03, -1.0932e-02],\n",
              "         [-8.2267e-03, -1.7116e-02, -8.1589e-03,  ...,  3.0049e-03,\n",
              "           1.5278e-02,  5.2204e-03],\n",
              "         [-1.5055e-02, -6.0740e-03,  1.0013e-02,  ..., -1.5250e-02,\n",
              "          -2.5661e-03, -7.1009e-03]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.2334e-02,  4.4303e-03,  1.1054e-02,  ..., -1.1766e-02,\n",
              "          -4.1534e-03,  8.7974e-04],\n",
              "         [-3.6210e-03, -1.2146e-02,  6.9922e-03,  ...,  1.4349e-02,\n",
              "          -1.5415e-02, -1.0933e-02],\n",
              "         [-8.4633e-03, -3.7140e-03, -8.8618e-03,  ...,  8.3190e-03,\n",
              "           1.5754e-02,  1.2235e-03],\n",
              "         ...,\n",
              "         [-1.8809e-03,  3.5489e-03,  4.5051e-03,  ...,  8.4359e-03,\n",
              "           1.9730e-04, -2.8944e-03],\n",
              "         [-3.2545e-03,  1.6351e-02, -1.4767e-02,  ...,  4.3159e-03,\n",
              "           1.5956e-02,  8.2254e-03],\n",
              "         [ 1.5634e-02,  5.8175e-03,  5.9979e-04,  ...,  1.1497e-02,\n",
              "           3.3772e-03,  6.7179e-03]],\n",
              "\n",
              "        [[ 7.7533e-03,  1.5527e-02, -5.4988e-03,  ..., -1.1192e-02,\n",
              "           1.1911e-02, -4.7018e-03],\n",
              "         [-9.9133e-03,  1.7534e-02, -9.2933e-03,  ...,  8.2324e-03,\n",
              "           6.0397e-03,  1.5699e-02],\n",
              "         [ 3.6703e-03, -2.5786e-03, -1.1385e-02,  ..., -9.2329e-03,\n",
              "           4.9725e-03, -8.1777e-03],\n",
              "         ...,\n",
              "         [ 5.7895e-03,  4.0886e-03,  4.2732e-03,  ...,  1.1066e-02,\n",
              "           1.5116e-02,  5.3976e-03],\n",
              "         [ 6.9853e-03,  1.6974e-02, -4.6838e-03,  ..., -1.2000e-02,\n",
              "           1.5951e-02, -1.6784e-02],\n",
              "         [ 1.5185e-02, -1.6183e-02, -7.9106e-03,  ..., -5.2335e-04,\n",
              "          -1.4473e-02,  1.5822e-02]],\n",
              "\n",
              "        [[ 1.4456e-02,  6.8649e-03, -8.1118e-03,  ..., -3.5438e-03,\n",
              "           1.1496e-02, -1.2346e-02],\n",
              "         [-3.8528e-03,  1.4973e-02, -1.6102e-02,  ..., -9.3577e-03,\n",
              "          -1.7771e-02, -3.7795e-03],\n",
              "         [ 1.1065e-02, -1.2008e-04, -1.3288e-02,  ..., -5.8848e-03,\n",
              "          -4.9725e-03,  8.8354e-03],\n",
              "         ...,\n",
              "         [-1.6562e-03,  1.0250e-02, -4.9264e-03,  ...,  8.5188e-03,\n",
              "           1.1517e-02,  2.8223e-03],\n",
              "         [ 1.6089e-02,  4.6889e-03,  1.5033e-02,  ...,  1.3669e-03,\n",
              "          -1.6724e-02, -3.9043e-03],\n",
              "         [ 6.3855e-03, -5.7994e-04,  5.5473e-04,  ..., -1.4167e-02,\n",
              "           5.1814e-03,  6.2629e-03]]], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sln7_yqA0651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4d99f6-4f7b-4052-d6ab-ee1674479aff"
      },
      "source": [
        "generator[0].weight.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 64, 7, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMFFTGQ0651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3943271-8e29-4749-90cc-44ed51108fa1"
      },
      "source": [
        "generator[0].bias"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxJ6gVze0653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f88188-78f2-4b4f-8105-fb1aa733e342"
      },
      "source": [
        "generator[0].bias.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohr9EW-y0654"
      },
      "source": [
        "### b.1) Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGDLcmK00654"
      },
      "source": [
        "def discriminator_model():\n",
        "    model = nn.Sequential()\n",
        "    model.add_module(\"Conv2D1\", nn.Conv2d(1, 2, kernel_size=5, stride=1, padding=2))\n",
        "    model.add_module(\"Pooling1\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
        "    model.add_module(\"Dropout1\", nn.Dropout(0.3))\n",
        "    \n",
        "    model.add_module(\"Conv2D2\", nn.Conv2d(2, 2, kernel_size=5, stride=1, padding=2))\n",
        "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D3\", nn.Conv2d(2, 1, kernel_size=5, stride=1, padding=0))\n",
        "    model.add_module(\"LeakyRelu3\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Flatten1\", nn.Flatten())\n",
        "    \n",
        "    model.add_module(\"Dense1\", nn.Linear(100,100))\n",
        "    model.add_module(\"LeakyRelu4\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Dense2\", nn.Linear(100,64))\n",
        "    model.add_module(\"Tanh\", nn.Tanh())\n",
        "    \n",
        "    model.add_module(\"Dense3\", nn.Linear(64,1))\n",
        "    model.add_module(\"Sigmoid\", nn.Sigmoid())\n",
        "    return model\n",
        "discriminator = discriminator_model()\n",
        "#discriminator = discriminator.float()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eGFfyYO0655"
      },
      "source": [
        "### b.2) Inspect the discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fqwNgL5J0655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e13cd5-cc3c-4e85-8430-0e9cd68f50a0"
      },
      "source": [
        "print(discriminator)\n",
        "discriminator(fake_im_not_trained)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
            "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
            "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
            "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
            "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (Tanh): Tanh()\n",
            "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (Sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5103]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTX4zp9c0655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97d4b05-7a5d-43a7-93b8-ab2b35f992f8"
      },
      "source": [
        "discriminator.apply(weights_init)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
              "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
              "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
              "  (Tanh): Tanh()\n",
              "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (Sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U8TOF5r0655"
      },
      "source": [
        "### b.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yXCZgM80656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87ca5450-5024-49fb-d7e3-b7c0d60352ef"
      },
      "source": [
        "discriminator[0].weight[0].type()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCKCE5rX0656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5216a9-f086-42e8-dec8-17caa7157385"
      },
      "source": [
        "discriminator[0].weight.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u4FdvnE0657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75231657-dc79-46cc-bc22-de0795cde67a"
      },
      "source": [
        "discriminator[0].bias"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFVYDoT0657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d606112-145e-4e3e-fb01-3e5e4a3d4df1"
      },
      "source": [
        "discriminator[0].bias.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Itee_8M0657"
      },
      "source": [
        "## 4. Loss & Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQrC1KNF0658"
      },
      "source": [
        "### 4.a) Generator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJbFTAz0658"
      },
      "source": [
        "cross_entropy = nn.BCEWithLogitsLoss()\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(torch.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzHIkuZM0658"
      },
      "source": [
        "### 4.b) Discriminator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDIX2a000659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "5ad5868d-503a-4491-9068-16aa03c8cf5c"
      },
      "source": [
        "def real_discriminator_loss(real_output):\n",
        "    return  cross_entropy(torch.ones_like(real_output), real_output)\n",
        "\n",
        "def fake_discriminator_loss(fake_output):\n",
        "    return cross_entropy(torch.zeros_like(fake_output), fake_output)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-74c608f165fc>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return  real_loss = cross_entropy(torch.ones_like(real_output), real_output)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7hrseRk0659"
      },
      "source": [
        "## 4.c) Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hic_TlMX0659"
      },
      "source": [
        "generator_optimizer = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-3)\n",
        "\n",
        "#train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy') # only for discriminator\n",
        "\n",
        "def correct_classification(y_true, y_prob):\n",
        "    assert y_true.size() == y_prob.size()\n",
        "    y_prob = (y_prob > 0.5).float()\n",
        "    return (y_true == y_prob).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYLo8yIj0659"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs8u8LUz065-"
      },
      "source": [
        "# This annotation causes the function to be \"compiled\".\n",
        "#@tf.function\n",
        "def train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size = 100):\n",
        "    gen_loss_tot = []\n",
        "    disc_loss_tot = []\n",
        "    disc_acc_real_tot = 0\n",
        "    disc_acc_fake_tot = 0\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    for beg_i in range(0, x_train_pt.shape[0], batch_size):\n",
        "        x_train_batch_pt = x_train_pt[beg_i:beg_i + batch_size]\n",
        "\n",
        "        x_fake_batch_pt = torch.rand([batch_size, 100, 1, 1])\n",
        "        \n",
        "        discriminator_optimizer.zero_grad()\n",
        "        real_output = discriminator(x_train_batch_pt.float()).view(-1)\n",
        "        disc_loss_real = real_discriminator_loss(real_output)\n",
        "        disc_loss_real.backward()\n",
        "        \n",
        "        generated_images = generator(x_fake_batch_pt)\n",
        "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
        "        disc_loss_fake = fake_discriminator_loss(fake_output)\n",
        "        disc_loss_fake.backward()\n",
        "        err = disc_loss_fake + disc_loss_real\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        \n",
        "        # optimize generator\n",
        "        generator_optimizer.zero_grad()\n",
        "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        gen_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "        \n",
        "        gen_loss_tot.append(gen_loss.mean().item())\n",
        "        disc_loss_tot.append(err.mean().item())\n",
        "        disc_acc_real_tot += correct_classification(torch.ones_like(real_output), real_output)\n",
        "        disc_acc_fake_tot += correct_classification(torch.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    disc_acc_real_tot = disc_acc_real_tot/x_train_pt.size(0)\n",
        "    disc_acc_fake_tot = disc_acc_fake_tot/x_train_pt.size(0)\n",
        "    disc_acc_tot = np.mean([disc_acc_real_tot, disc_acc_fake_tot])\n",
        "    return gen_loss_tot, disc_loss_tot, disc_acc_tot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F-ILomMn065-"
      },
      "source": [
        "train_losses_generator_pt = []\n",
        "train_losses_discriminator_pt = []\n",
        "train_acc_discriminator_pt = []\n",
        "epochs = 15\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gen_loss, disc_loss, disc_acc = train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
        "    gen_loss = np.mean(gen_loss)\n",
        "    disc_loss = np.mean(disc_loss)\n",
        "    train_losses_generator_pt.append(gen_loss)\n",
        "    train_losses_discriminator_pt.append(disc_loss)\n",
        "    train_acc_discriminator_pt.append(disc_acc*100)\n",
        "\n",
        "\n",
        "    template = (\"Epoch {}, Loss_Generator: {}, Loss_Discriminator: {}, Discriminator_Accuracy: {}\")\n",
        "    print(template.format(epoch+1, gen_loss, disc_loss, disc_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Mbb_M065-"
      },
      "source": [
        "### b) Training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8-7QBvL065_"
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(train_acc_discriminator_pt)\n",
        "plt.title('discriminator accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['discriminator_train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8W0zvk065_"
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(train_losses_generator_pt)\n",
        "plt.plot(train_losses_discriminator_pt)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['generator', 'discriminator'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVnypYA065_"
      },
      "source": [
        "### c1) Generator output before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMDDynAD066A"
      },
      "source": [
        "fake_im_not_trained = fake_im_not_trained.detach().numpy() * 255\n",
        "fake_im_not_trained = fake_im_not_trained.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im_not_trained, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3KjkI-066A"
      },
      "source": [
        "### c2) Generator output after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfqPBgZo066A"
      },
      "source": [
        "seed2 = torch.rand([1, 100, 1, 1])\n",
        "generator.train(False)\n",
        "fake_im = generator(seed2)\n",
        "fake_im = fake_im.detach().numpy() * 255\n",
        "fake_im = fake_im.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}