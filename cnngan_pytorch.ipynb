{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/blob/master/cnngan_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVotrWM-065f"
   },
   "source": [
    "# Implementing a CNNGAN with pytroch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt9oTYk6065n"
   },
   "source": [
    "## 1. Import and Preprocessing\n",
    "### a) Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QOvHT87j065o"
   },
   "outputs": [],
   "source": [
    "# Load required packages - data handling & plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load required packages - deep learning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2kizsA7065p",
    "outputId": "3c3218e6-1350-43c9-a305-57f635d4cc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 1.8.1+cu101\n",
      "python: 3.7.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensorflow: {torch.__version__}\")\n",
    "import sys\n",
    "print(f\"python: {sys.version[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7um10LNJ065q"
   },
   "source": [
    "### b) Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvOi4NVI065r"
   },
   "outputs": [],
   "source": [
    "# I exceeded my git LFS bandwidth limit for this month, thus the file cannot be loaded from git\n",
    "train_data = pd.read_csv('https://media.githubusercontent.com/media/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/master/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "ukf4AIqY065r",
    "outputId": "660dc9b8-3357-41b3-d25d-5ad5bf7e3107"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>107</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>220</td>\n",
       "      <td>214</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>222</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>134</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>214</td>\n",
       "      <td>163</td>\n",
       "      <td>146</td>\n",
       "      <td>165</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>183</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>165</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>188</td>\n",
       "      <td>163</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>249</td>\n",
       "      <td>207</td>\n",
       "      <td>197</td>\n",
       "      <td>202</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>116</td>\n",
       "      <td>112</td>\n",
       "      <td>136</td>\n",
       "      <td>147</td>\n",
       "      <td>144</td>\n",
       "      <td>121</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
       "0      2       0       0       0  ...         0         0         0         0\n",
       "1      9       0       0       0  ...         0         0         0         0\n",
       "2      6       0       0       0  ...         0         0         0         0\n",
       "3      0       0       0       0  ...         0         0         0         0\n",
       "4      3       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqXVdux_065s"
   },
   "outputs": [],
   "source": [
    "train_images = train_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "54zxTjsL065s",
    "outputId": "1cab75e6-39d2-4d77-e474-ca3d175f94e6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images.values[0].reshape(28,28), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDAY2krK065t"
   },
   "source": [
    "### c) Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT0M8L-K065t"
   },
   "outputs": [],
   "source": [
    "# use maximum normalization\n",
    "train_images = train_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "msQ_biny065u",
    "outputId": "d3691f75-06cb-45ae-c1b9-3645e8495583"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>pixel40</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3    pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
       "0     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "1     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "2     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "3     0.0     0.0     0.0  0.003922  ...       0.0       0.0       0.0       0.0\n",
       "4     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hvl4Hst065u"
   },
   "source": [
    "\n",
    "## 2. Model specific data preparation (tensorflow)\n",
    "## a) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts0H5owM065v"
   },
   "outputs": [],
   "source": [
    "x_train_pt = torch.from_numpy(train_images.values.reshape((-1, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAjl91Lm065v"
   },
   "source": [
    "### b) Tensor view of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR0SONiS065w",
    "outputId": "2baea354-4418-4611-b646-a4c6bb53de38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 237,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xx2B52_n065w",
    "outputId": "f679b820-b0a9-46ae-b8c1-61ef6f3ed8f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 209,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d-1O3ac065w",
    "outputId": "45f7af07-88b2-4b2b-829c-74f770d25917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.9882, 0.9176, 0.9333,\n",
       "        0.8784, 0.8431, 0.8431, 0.8980, 0.4235, 0.7059, 0.8118, 0.8392, 0.8784,\n",
       "        0.9059, 0.9765, 0.9961, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pt[0][0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeUJVqsI065x"
   },
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WsQu8jb2065x"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "      nn.init.uniform_(m.weight.data, -1,1)\n",
    "      nn.init.zeros_(m.bias.data)\n",
    "  if isinstance(m, nn.Conv2d):\n",
    "      nn.init.uniform_(m.weight.data, -1, 1)\n",
    "      nn.init.zeros_(m.bias.data)\n",
    "  if isinstance(m, nn.ConvTranspose2d):\n",
    "      nn.init.uniform_(m.weight.data, -1, 1)\n",
    "      nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "C4KeOa9K065y"
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, channels, height, width):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = (channels, height, width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUFkLr4M065y"
   },
   "source": [
    "### a.1) Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XQ9ReExW065z"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = nn.Sequential()\n",
    "    model.add_module(\"Conv2D1\", nn.ConvTranspose2d(100, 64, 7, stride=1, padding=0, bias=True))\n",
    "    #model.add_module(\"Reshape\", Reshape(64, 7, 7))\n",
    "    model.add_module(\"Batchnorm1\", nn.BatchNorm2d(64))\n",
    "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Conv2D2\", nn.ConvTranspose2d(64, 32, (8,8), stride=(1,1), padding=0, bias=True))\n",
    "    model.add_module(\"Batchnorm2\", nn.BatchNorm2d(32))\n",
    "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Conv2D3\", nn.ConvTranspose2d(32, 1, (15,15), stride=1, padding=0, bias=True))\n",
    "    model.add_module(\"Batchnorm3\", nn.BatchNorm2d(1))\n",
    "    model.add_module(\"Sigmoid1\", nn.Sigmoid())\n",
    "    return model\n",
    "generator = generator_model()\n",
    "#generator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7tqK5yB0650"
   },
   "source": [
    "###  a.2) Inspect the generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoiTZ37X0650",
    "outputId": "47590bb6-5177-4841-8e0b-ab66fac7e2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
      "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
      "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
      "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (Sigmoid1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0v3fU5j0650",
    "outputId": "da8c0357-f1a7-41c8-e88c-2bc98bfafa1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
       "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
       "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (Sigmoid1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBZJiTRZ065z",
    "outputId": "88b33ddb-4957-41cb-8ae8-730eeeacd402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5230, 0.5461, 0.5439, 0.5035, 0.5890, 0.5871, 0.6494, 0.6215,\n",
       "           0.6066, 0.5580, 0.6030, 0.5585, 0.5055, 0.5523, 0.5500, 0.4284,\n",
       "           0.5115, 0.5150, 0.5896, 0.5708, 0.5741, 0.6088, 0.5289, 0.5867,\n",
       "           0.5567, 0.5176, 0.5259, 0.5387],\n",
       "          [0.5218, 0.5063, 0.5966, 0.5712, 0.4410, 0.5496, 0.6267, 0.5774,\n",
       "           0.4489, 0.4983, 0.5680, 0.5629, 0.4645, 0.5490, 0.5110, 0.4709,\n",
       "           0.5312, 0.6111, 0.6946, 0.5762, 0.6348, 0.6462, 0.5891, 0.5786,\n",
       "           0.5524, 0.5204, 0.4827, 0.5296],\n",
       "          [0.5179, 0.5240, 0.5300, 0.4851, 0.4820, 0.4725, 0.4746, 0.3542,\n",
       "           0.4450, 0.3770, 0.6664, 0.4712, 0.4705, 0.5512, 0.5724, 0.3200,\n",
       "           0.3519, 0.6568, 0.7151, 0.6054, 0.5777, 0.6353, 0.5958, 0.6671,\n",
       "           0.5144, 0.5168, 0.5702, 0.5192],\n",
       "          [0.5240, 0.5575, 0.4650, 0.4680, 0.3841, 0.4281, 0.2280, 0.3393,\n",
       "           0.3656, 0.2630, 0.3052, 0.2906, 0.4946, 0.3898, 0.6375, 0.5036,\n",
       "           0.2883, 0.6569, 0.6881, 0.4240, 0.4960, 0.4888, 0.5068, 0.5789,\n",
       "           0.5583, 0.5744, 0.4557, 0.5656],\n",
       "          [0.5608, 0.4914, 0.5379, 0.4995, 0.5267, 0.6241, 0.2889, 0.3430,\n",
       "           0.4280, 0.1302, 0.3452, 0.2349, 0.4227, 0.2999, 0.4997, 0.5253,\n",
       "           0.2885, 0.5502, 0.5285, 0.7385, 0.3239, 0.7386, 0.5506, 0.5131,\n",
       "           0.6739, 0.5045, 0.5421, 0.4928],\n",
       "          [0.5772, 0.5596, 0.5417, 0.4219, 0.4347, 0.4264, 0.2729, 0.2734,\n",
       "           0.8197, 0.4375, 0.3129, 0.2466, 0.3368, 0.6794, 0.7415, 0.0626,\n",
       "           0.5303, 0.6821, 0.3864, 0.5448, 0.7299, 0.7613, 0.7783, 0.6685,\n",
       "           0.6902, 0.4159, 0.4929, 0.5291],\n",
       "          [0.5662, 0.4964, 0.5196, 0.4279, 0.4139, 0.6051, 0.1963, 0.0524,\n",
       "           0.0961, 0.3056, 0.3474, 0.6979, 0.5004, 0.6571, 0.2007, 0.3486,\n",
       "           0.1596, 0.4199, 0.2727, 0.6554, 0.7556, 0.7782, 0.6582, 0.6137,\n",
       "           0.5516, 0.5892, 0.4293, 0.4889],\n",
       "          [0.5517, 0.5120, 0.3387, 0.3162, 0.4134, 0.1791, 0.0706, 0.0736,\n",
       "           0.2279, 0.0148, 0.5674, 0.2481, 0.6110, 0.9099, 0.2493, 0.3887,\n",
       "           0.6384, 0.6163, 0.6011, 0.5164, 0.5901, 0.3956, 0.3745, 0.5740,\n",
       "           0.4688, 0.4396, 0.5491, 0.5001],\n",
       "          [0.6071, 0.4190, 0.3912, 0.3080, 0.4145, 0.1541, 0.0514, 0.0249,\n",
       "           0.0355, 0.1521, 0.3806, 0.4406, 0.0457, 0.0398, 0.4168, 0.7785,\n",
       "           0.2466, 0.7417, 0.5639, 0.9004, 0.7368, 0.6603, 0.5694, 0.4566,\n",
       "           0.2390, 0.5041, 0.5973, 0.4582],\n",
       "          [0.6745, 0.4887, 0.5144, 0.3428, 0.1769, 0.1583, 0.0836, 0.0354,\n",
       "           0.0751, 0.0166, 0.3970, 0.0824, 0.1417, 0.7987, 0.9652, 0.7453,\n",
       "           0.1800, 0.9335, 0.8050, 0.6421, 0.1731, 0.4660, 0.3094, 0.2100,\n",
       "           0.4379, 0.3590, 0.3788, 0.5839],\n",
       "          [0.6078, 0.5028, 0.6413, 0.3666, 0.3372, 0.1407, 0.2470, 0.0474,\n",
       "           0.5058, 0.6011, 0.6820, 0.3699, 0.3043, 0.4397, 0.3843, 0.7473,\n",
       "           0.9051, 0.2598, 0.3788, 0.6061, 0.6233, 0.4636, 0.7536, 0.3308,\n",
       "           0.4076, 0.5025, 0.3047, 0.4925],\n",
       "          [0.5820, 0.5047, 0.3253, 0.5306, 0.4316, 0.1395, 0.2504, 0.1961,\n",
       "           0.1496, 0.5910, 0.9336, 0.2097, 0.5494, 0.6612, 0.1724, 0.9303,\n",
       "           0.7070, 0.8519, 0.1823, 0.7177, 0.0887, 0.6722, 0.4086, 0.6008,\n",
       "           0.1524, 0.5654, 0.3755, 0.5322],\n",
       "          [0.5845, 0.5312, 0.3144, 0.1413, 0.4752, 0.1504, 0.5016, 0.4016,\n",
       "           0.2583, 0.1769, 0.8892, 0.9497, 0.2916, 0.3333, 0.7225, 0.7511,\n",
       "           0.6737, 0.4468, 0.7514, 0.1120, 0.5953, 0.0957, 0.2309, 0.1746,\n",
       "           0.2103, 0.3209, 0.3046, 0.5696],\n",
       "          [0.5350, 0.4098, 0.5392, 0.2139, 0.2192, 0.3688, 0.2176, 0.3309,\n",
       "           0.8448, 0.5112, 0.2821, 0.5541, 0.4269, 0.4300, 0.5629, 0.7554,\n",
       "           0.3153, 0.8117, 0.0757, 0.3136, 0.0188, 0.3984, 0.2954, 0.4679,\n",
       "           0.1934, 0.2721, 0.2665, 0.5477],\n",
       "          [0.5449, 0.4761, 0.3325, 0.3494, 0.4137, 0.8862, 0.5862, 0.0918,\n",
       "           0.1663, 0.4728, 0.4070, 0.0890, 0.1807, 0.1524, 0.0528, 0.3745,\n",
       "           0.4625, 0.5873, 0.1409, 0.5610, 0.1523, 0.3205, 0.5823, 0.4028,\n",
       "           0.2619, 0.2725, 0.4017, 0.4260],\n",
       "          [0.5093, 0.3763, 0.5567, 0.6481, 0.6315, 0.4590, 0.6587, 0.2840,\n",
       "           0.7012, 0.5276, 0.8051, 0.1137, 0.9445, 0.6980, 0.2069, 0.7486,\n",
       "           0.9121, 0.9487, 0.7503, 0.7436, 0.6424, 0.5873, 0.3506, 0.3061,\n",
       "           0.2277, 0.5555, 0.3120, 0.5244],\n",
       "          [0.4451, 0.5419, 0.6285, 0.5857, 0.5351, 0.8196, 0.2804, 0.6851,\n",
       "           0.5794, 0.6949, 0.0355, 0.0557, 0.4158, 0.2322, 0.9638, 0.6687,\n",
       "           0.8828, 0.6350, 0.8024, 0.8203, 0.0779, 0.7494, 0.2591, 0.3135,\n",
       "           0.4950, 0.1435, 0.4715, 0.4300],\n",
       "          [0.4540, 0.5531, 0.4844, 0.6820, 0.6385, 0.5514, 0.7751, 0.4254,\n",
       "           0.4456, 0.6129, 0.8889, 0.4059, 0.6012, 0.6050, 0.2800, 0.5180,\n",
       "           0.7573, 0.2690, 0.6318, 0.9280, 0.9062, 0.8860, 0.4154, 0.7553,\n",
       "           0.5572, 0.2836, 0.4956, 0.5362],\n",
       "          [0.4987, 0.5849, 0.5498, 0.6003, 0.6563, 0.6388, 0.6385, 0.4036,\n",
       "           0.7935, 0.0808, 0.3663, 0.7238, 0.2892, 0.6645, 0.6728, 0.2425,\n",
       "           0.8917, 0.9188, 0.3515, 0.6621, 0.6856, 0.8885, 0.5527, 0.7253,\n",
       "           0.6521, 0.4454, 0.5350, 0.5133],\n",
       "          [0.5524, 0.6032, 0.5526, 0.3898, 0.6958, 0.6563, 0.5643, 0.6617,\n",
       "           0.4260, 0.6766, 0.2196, 0.7483, 0.8082, 0.1554, 0.3662, 0.3069,\n",
       "           0.6358, 0.4100, 0.2111, 0.8105, 0.7949, 0.4265, 0.9660, 0.5613,\n",
       "           0.4272, 0.3916, 0.4598, 0.4685],\n",
       "          [0.5214, 0.4923, 0.4405, 0.6293, 0.6746, 0.8224, 0.5791, 0.1936,\n",
       "           0.8151, 0.7381, 0.3145, 0.4656, 0.5151, 0.8627, 0.2245, 0.1458,\n",
       "           0.3764, 0.6684, 0.2957, 0.9724, 0.5501, 0.7989, 0.6935, 0.6148,\n",
       "           0.5894, 0.6383, 0.4699, 0.5459],\n",
       "          [0.5304, 0.5028, 0.4428, 0.7780, 0.7044, 0.7565, 0.6771, 0.7515,\n",
       "           0.4255, 0.5731, 0.8416, 0.7569, 0.7393, 0.6306, 0.5734, 0.1586,\n",
       "           0.5882, 0.6436, 0.4456, 0.7508, 0.7682, 0.8067, 0.8465, 0.5834,\n",
       "           0.7163, 0.4545, 0.4180, 0.5691],\n",
       "          [0.5445, 0.5161, 0.4417, 0.6269, 0.7139, 0.3319, 0.5525, 0.5626,\n",
       "           0.9385, 0.7619, 0.5462, 0.2861, 0.8338, 0.7476, 0.7408, 0.4153,\n",
       "           0.5893, 0.7482, 0.5392, 0.7875, 0.5172, 0.7758, 0.5401, 0.7282,\n",
       "           0.5685, 0.4716, 0.4081, 0.4725],\n",
       "          [0.5304, 0.4943, 0.5034, 0.5658, 0.5664, 0.5887, 0.3521, 0.7291,\n",
       "           0.6280, 0.5675, 0.7808, 0.6703, 0.2924, 0.4624, 0.7890, 0.6724,\n",
       "           0.7858, 0.4701, 0.4045, 0.4865, 0.7260, 0.7056, 0.5688, 0.8395,\n",
       "           0.6164, 0.5981, 0.5324, 0.5908],\n",
       "          [0.5205, 0.5196, 0.5004, 0.4565, 0.5219, 0.4918, 0.5789, 0.4652,\n",
       "           0.6756, 0.5698, 0.3992, 0.6469, 0.7027, 0.4331, 0.4030, 0.5834,\n",
       "           0.4968, 0.4744, 0.7619, 0.4651, 0.6205, 0.7247, 0.6940, 0.5324,\n",
       "           0.6769, 0.4715, 0.4079, 0.5336],\n",
       "          [0.5048, 0.4769, 0.4965, 0.4619, 0.5020, 0.4700, 0.4640, 0.5474,\n",
       "           0.4907, 0.5607, 0.4173, 0.6175, 0.6087, 0.2635, 0.2297, 0.6108,\n",
       "           0.6056, 0.3315, 0.6113, 0.6832, 0.5616, 0.6009, 0.6157, 0.5823,\n",
       "           0.6316, 0.4532, 0.4538, 0.5232],\n",
       "          [0.5174, 0.5263, 0.5027, 0.4701, 0.4459, 0.5139, 0.5459, 0.4993,\n",
       "           0.5633, 0.5544, 0.4568, 0.4254, 0.4654, 0.4447, 0.4748, 0.5374,\n",
       "           0.5237, 0.6633, 0.6358, 0.6143, 0.6717, 0.6226, 0.5527, 0.5164,\n",
       "           0.4816, 0.4843, 0.5351, 0.5278],\n",
       "          [0.5274, 0.5356, 0.5356, 0.5097, 0.4707, 0.5499, 0.4764, 0.5547,\n",
       "           0.4813, 0.5101, 0.4937, 0.5357, 0.6040, 0.5044, 0.4882, 0.5847,\n",
       "           0.5916, 0.4436, 0.5465, 0.5490, 0.5074, 0.5222, 0.5219, 0.5287,\n",
       "           0.5156, 0.5157, 0.5333, 0.5170]]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated image not trained\n",
    "fake_im_not_trained = generator(torch.normal(0, 1, size=[1, 100, 1, 1]))\n",
    "# check output shape of generator\n",
    "fake_im_not_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfrxvvCj0651"
   },
   "source": [
    "### a.3) Inspect the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yKD8kav0651",
    "outputId": "c5183d4a-aa4a-4fc4-a185-9768d8247590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7559,  0.2496, -0.2291,  ..., -0.6878, -0.3684,  0.7580],\n",
       "         [ 0.2487,  0.6512,  0.7564,  ..., -0.8068, -0.6948, -0.3514],\n",
       "         [-0.2338,  0.0330,  0.7632,  ...,  0.3809,  0.5917, -0.6294],\n",
       "         ...,\n",
       "         [-0.6728, -0.3124,  0.7846,  ...,  0.2179,  0.0990,  0.0612],\n",
       "         [ 0.8130, -0.4786,  0.0728,  ...,  0.1687,  0.4673,  0.1248],\n",
       "         [ 0.6978,  0.6183,  0.2969,  ..., -0.2764,  0.7022, -0.5189]],\n",
       "\n",
       "        [[ 0.3306,  0.7710, -0.6513,  ..., -0.8253, -0.9600, -0.4408],\n",
       "         [-0.9396,  0.7716,  0.0869,  ...,  0.8743, -0.8638, -0.2973],\n",
       "         [-0.5154,  0.1877, -0.8550,  ..., -0.3349, -0.5136,  0.4769],\n",
       "         ...,\n",
       "         [ 0.9944, -0.9518, -0.6705,  ..., -0.8086,  0.2530,  0.2341],\n",
       "         [ 0.3775,  0.5600,  0.3757,  ...,  0.1892,  0.6948, -0.3136],\n",
       "         [ 0.0879,  0.8241, -0.9980,  ..., -0.2070,  0.7608,  0.1316]],\n",
       "\n",
       "        [[ 0.6309,  0.8334, -0.1804,  ...,  0.2255,  0.3319, -0.5827],\n",
       "         [ 0.2012, -0.1980, -0.1039,  ...,  0.4409, -0.1256, -0.3361],\n",
       "         [-0.7038, -0.6388, -0.3622,  ..., -0.5755,  0.8658,  0.0222],\n",
       "         ...,\n",
       "         [-0.9264,  0.5260, -0.7911,  ...,  0.4502,  0.8987, -0.8043],\n",
       "         [-0.2116, -0.8669,  0.2720,  ..., -0.4656, -0.9335, -0.5285],\n",
       "         [-0.5990, -0.4965, -0.7970,  ..., -0.5205,  0.5354,  0.0454]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3261, -0.6080,  0.9236,  ...,  0.7400,  0.1303, -0.2409],\n",
       "         [-0.1286, -0.7923, -0.1858,  ..., -0.0124, -0.5243,  0.0545],\n",
       "         [ 0.8916,  0.2589, -0.2571,  ...,  0.9373,  0.0763, -0.4387],\n",
       "         ...,\n",
       "         [ 0.2971, -0.7448,  0.8544,  ...,  0.4961,  0.6841,  0.7610],\n",
       "         [-0.1328,  0.8761,  0.9123,  ...,  0.2988, -0.9877,  0.8237],\n",
       "         [ 0.2142,  0.8848, -0.2418,  ...,  0.7027,  0.7483,  0.1684]],\n",
       "\n",
       "        [[ 0.0874, -0.1108, -0.2043,  ..., -0.1502, -0.0800,  0.0595],\n",
       "         [-0.5821, -0.1409, -0.3769,  ..., -0.0994,  0.2912,  0.5057],\n",
       "         [ 0.7161, -0.1844,  0.4700,  ..., -0.9930, -0.4864, -0.1435],\n",
       "         ...,\n",
       "         [ 0.7614,  0.4982,  0.6645,  ...,  0.5792,  0.5234, -0.3908],\n",
       "         [-0.1022,  0.2780, -0.8573,  ..., -0.4335,  0.6940,  0.2817],\n",
       "         [-0.7489,  0.7053, -0.7917,  ...,  0.7139,  0.9851,  0.7117]],\n",
       "\n",
       "        [[ 0.6962,  0.3786, -0.9194,  ...,  0.5529, -0.4528,  0.7498],\n",
       "         [-0.8384,  0.8922, -0.2553,  ...,  0.4874,  0.9747,  0.8070],\n",
       "         [ 0.5447,  0.0538,  0.6187,  ...,  0.7930,  0.7828,  0.7345],\n",
       "         ...,\n",
       "         [-0.2182,  0.0725, -0.2227,  ..., -0.3683,  0.6637,  0.9816],\n",
       "         [ 0.4366, -0.4860,  0.8135,  ..., -0.5217, -0.9763,  0.1145],\n",
       "         [-0.3155,  0.8705,  0.4342,  ..., -0.7707, -0.5283, -0.2155]]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sln7_yqA0651",
    "outputId": "3953f8a8-1283-4d47-a3e6-e6d8ede3b769"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 7, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJMFFTGQ0651",
    "outputId": "50b49db7-1ef9-465e-9389-98caf84bae74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxJ6gVze0653",
    "outputId": "b5a05f6c-17fe-4927-997b-c71adcd8cfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohr9EW-y0654"
   },
   "source": [
    "### b.1) Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rGDLcmK00654"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = nn.Sequential()\n",
    "    model.add_module(\"Conv2D1\", nn.Conv2d(1, 2, kernel_size=5, stride=1, padding=2))\n",
    "    model.add_module(\"Pooling1\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
    "    model.add_module(\"Dropout1\", nn.Dropout(0.3))\n",
    "    \n",
    "    model.add_module(\"Conv2D2\", nn.Conv2d(2, 2, kernel_size=5, stride=1, padding=2))\n",
    "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Conv2D3\", nn.Conv2d(2, 1, kernel_size=5, stride=1, padding=0))\n",
    "    model.add_module(\"LeakyRelu3\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Flatten1\", nn.Flatten())\n",
    "    \n",
    "    model.add_module(\"Dense1\", nn.Linear(100,100))\n",
    "    model.add_module(\"LeakyRelu4\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Dense2\", nn.Linear(100,64))\n",
    "    model.add_module(\"Tanh\", nn.Tanh())\n",
    "    \n",
    "    model.add_module(\"Dense3\", nn.Linear(64,1))\n",
    "    model.add_module(\"Sigmoid\", nn.Sigmoid())\n",
    "    return model\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eGFfyYO0655"
   },
   "source": [
    "### b.2) Inspect the discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqwNgL5J0655",
    "outputId": "394bdd68-8863-46f1-be11-70955b8455de",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
      "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
      "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
      "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
      "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (Tanh): Tanh()\n",
      "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (Sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4763]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(discriminator)\n",
    "discriminator(fake_im_not_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTX4zp9c0655",
    "outputId": "85307e84-6a4d-4b5b-d2d3-0a56a97fc39d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
       "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
       "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
       "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (Tanh): Tanh()\n",
       "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U8TOF5r0655"
   },
   "source": [
    "### b.3) Inspect the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4yXCZgM80656",
    "outputId": "a32b574e-93a3-417f-be81-2e0431867e6a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 224,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].weight[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCKCE5rX0656",
    "outputId": "b581429a-d0b0-471c-ee73-528d64d78033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u4FdvnE0657",
    "outputId": "7c3f9b44-0eaf-4ecc-8d76-13e0ead29eb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 226,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkFVYDoT0657",
    "outputId": "d18b394a-fc80-48b2-e9d3-be500f816a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 227,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Itee_8M0657"
   },
   "source": [
    "## 4. Loss & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQrC1KNF0658"
   },
   "source": [
    "### 4.a) Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUJbFTAz0658"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCEWithLogitsLoss()\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(torch.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzHIkuZM0658"
   },
   "source": [
    "### 4.b) Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDIX2a000659"
   },
   "outputs": [],
   "source": [
    "def real_discriminator_loss(real_output):\n",
    "    return  cross_entropy(torch.ones_like(real_output), real_output)\n",
    "\n",
    "def fake_discriminator_loss(fake_output):\n",
    "    return cross_entropy(torch.zeros_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7hrseRk0659"
   },
   "source": [
    "## 4.c) Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hic_TlMX0659"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = optim.Adam(generator.parameters(), lr=1e-2)\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-2)\n",
    "\n",
    "def correct_classification(y_true, y_prob):\n",
    "    assert y_true.size() == y_prob.size()\n",
    "    y_prob = (y_prob > 0.5).float()\n",
    "    return (y_true == y_prob).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYLo8yIj0659"
   },
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Gs8u8LUz065-"
   },
   "outputs": [],
   "source": [
    "# This annotation causes the function to be \"compiled\".\n",
    "#@tf.function\n",
    "def train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size = 100):\n",
    "    gen_loss_tot = []\n",
    "    disc_loss_tot = []\n",
    "    disc_acc_real_tot = 0\n",
    "    disc_acc_fake_tot = 0\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    for beg_i in range(0, x_train_pt.shape[0], batch_size):\n",
    "        x_train_batch_pt = x_train_pt[beg_i:beg_i + batch_size]\n",
    "\n",
    "        x_fake_batch_pt = torch.normal(0, 1, size=[batch_size, 100, 1, 1])\n",
    "        \n",
    "        discriminator_optimizer.zero_grad()\n",
    "        real_output = discriminator(x_train_batch_pt.float()).view(-1)\n",
    "        disc_loss_real = real_discriminator_loss(real_output)\n",
    "        disc_loss_real.backward()\n",
    "        \n",
    "        generated_images = generator(x_fake_batch_pt)\n",
    "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
    "        disc_loss_fake = fake_discriminator_loss(fake_output)\n",
    "        disc_loss_fake.backward()\n",
    "        err = disc_loss_fake + disc_loss_real\n",
    "        discriminator_optimizer.step()\n",
    "        \n",
    "        # optimize generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        gen_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        gen_loss_tot.append(gen_loss.mean().item())\n",
    "        disc_loss_tot.append(err.mean().item())\n",
    "        disc_acc_real_tot += correct_classification(torch.ones_like(real_output), real_output)\n",
    "        disc_acc_fake_tot += correct_classification(torch.zeros_like(fake_output), fake_output)\n",
    "\n",
    "    disc_acc_real_tot = disc_acc_real_tot/x_train_pt.size(0)\n",
    "    disc_acc_fake_tot = disc_acc_fake_tot/x_train_pt.size(0)\n",
    "    print([disc_acc_real_tot, disc_acc_fake_tot])\n",
    "    disc_acc_tot = np.mean([disc_acc_real_tot, disc_acc_fake_tot])\n",
    "    return gen_loss_tot, disc_loss_tot, disc_acc_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "F-ILomMn065-",
    "outputId": "06dae2b4-4755-4cdb-dec5-6e564594ea97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9985, 0.0]\n",
      "Epoch 1, Loss_Generator: 0.3137556545933088, Loss_Discriminator: 1.0079493055740991, Discriminator_Accuracy: 49.925000000000004\n",
      "[1.0, 0.0]\n",
      "Epoch 2, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 3, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 4, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 5, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 6, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 7, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-018828624942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-1cc16055fa9a>\u001b[0m in \u001b[0;36mtrain_step_pt\u001b[0;34m(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake_batch_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdisc_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_discriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdisc_loss_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses_generator_pt = []\n",
    "train_losses_discriminator_pt = []\n",
    "train_acc_discriminator_pt = []\n",
    "epochs = 15\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    gen_loss, disc_loss, disc_acc = train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
    "    gen_loss = np.mean(gen_loss)\n",
    "    disc_loss = np.mean(disc_loss)\n",
    "    train_losses_generator_pt.append(gen_loss)\n",
    "    train_losses_discriminator_pt.append(disc_loss)\n",
    "    train_acc_discriminator_pt.append(disc_acc*100)\n",
    "\n",
    "\n",
    "    template = (\"Epoch {}, Loss_Generator: {}, Loss_Discriminator: {}, Discriminator_Accuracy: {}\")\n",
    "    print(template.format(epoch+1, gen_loss, disc_loss, disc_acc*100))\n",
    "end = time.time()\n",
    "print(f\"Total training time{(end - start)/60.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGOH030LKOwE"
   },
   "outputs": [],
   "source": [
    "print(f\"Total training time{(end - start)/60.0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E88Mbb_M065-"
   },
   "source": [
    "### b) Training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8-7QBvL065_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(train_acc_discriminator_pt)\n",
    "plt.title('discriminator accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['discriminator_train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG8W0zvk065_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(train_losses_generator_pt)\n",
    "plt.plot(train_losses_discriminator_pt)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['generator', 'discriminator'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UiwHcmI4C_d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdVnypYA065_"
   },
   "source": [
    "### c1) Generator output before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xMDDynAD066A"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fake_im_not_trained = fake_im_not_trained.detach().numpy() * 255\n",
    "fake_im_not_trained = fake_im_not_trained.reshape((28,28))\n",
    "plt.figure()\n",
    "plt.imshow(fake_im_not_trained, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH3KjkI-066A"
   },
   "source": [
    "### c2) Generator output after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfqPBgZo066A"
   },
   "outputs": [],
   "source": [
    "seed2 = torch.normal(0, 1, size=[1, 100, 1, 1])\n",
    "generator.train(False)\n",
    "fake_im = generator(seed2)\n",
    "fake_im = fake_im.detach().numpy() * 255\n",
    "fake_im = fake_im.reshape((28,28))\n",
    "plt.figure()\n",
    "plt.imshow(fake_im, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDy-AvTmL6D4"
   },
   "source": [
    "## 6. References\n",
    "The presented model is based on a combination of two tutorials for deep cnn-gans:\n",
    "1) https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "\n",
    "2) https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_UcuzDvL6D4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "cnngan_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
