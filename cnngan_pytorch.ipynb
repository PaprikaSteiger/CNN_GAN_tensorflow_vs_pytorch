{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/blob/master/cnngan_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVotrWM-065f"
   },
   "source": [
    "# Implementing a CNNGAN with pytroch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt9oTYk6065n"
   },
   "source": [
    "## 1. Import and Preprocessing\n",
    "### a) Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOvHT87j065o"
   },
   "outputs": [],
   "source": [
    "# Load required packages - data handling & plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load required packages - deep learning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2kizsA7065p",
    "outputId": "3c3218e6-1350-43c9-a305-57f635d4cc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 1.8.1+cu101\n",
      "python: 3.7.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensorflow: {torch.__version__}\")\n",
    "import sys\n",
    "print(f\"python: {sys.version[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7um10LNJ065q"
   },
   "source": [
    "### b) Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9K_QRXq065r"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "del y_train\n",
    "del x_test\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvOi4NVI065r"
   },
   "outputs": [],
   "source": [
    "# I exceeded my git LFS bandwidth limit for this month, thus the file cannot be loaded from git\n",
    "# train_data = pd.read_csv('https://media.githubusercontent.com/media/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/master/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "ukf4AIqY065r",
    "outputId": "660dc9b8-3357-41b3-d25d-5ad5bf7e3107"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>107</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>211</td>\n",
       "      <td>220</td>\n",
       "      <td>214</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>222</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>134</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>214</td>\n",
       "      <td>163</td>\n",
       "      <td>146</td>\n",
       "      <td>165</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>183</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>165</td>\n",
       "      <td>160</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>188</td>\n",
       "      <td>163</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>249</td>\n",
       "      <td>207</td>\n",
       "      <td>197</td>\n",
       "      <td>202</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>116</td>\n",
       "      <td>112</td>\n",
       "      <td>136</td>\n",
       "      <td>147</td>\n",
       "      <td>144</td>\n",
       "      <td>121</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
       "0      2       0       0       0  ...         0         0         0         0\n",
       "1      9       0       0       0  ...         0         0         0         0\n",
       "2      6       0       0       0  ...         0         0         0         0\n",
       "3      0       0       0       0  ...         0         0         0         0\n",
       "4      3       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqXVdux_065s"
   },
   "outputs": [],
   "source": [
    "train_images = train_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "54zxTjsL065s",
    "outputId": "1cab75e6-39d2-4d77-e474-ca3d175f94e6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images.values[0].reshape(28,28), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDAY2krK065t"
   },
   "source": [
    "### c) Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT0M8L-K065t"
   },
   "outputs": [],
   "source": [
    "# use maximum normalization\n",
    "train_images = train_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "msQ_biny065u",
    "outputId": "d3691f75-06cb-45ae-c1b9-3645e8495583"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>pixel40</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3    pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
       "0     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "1     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "2     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "3     0.0     0.0     0.0  0.003922  ...       0.0       0.0       0.0       0.0\n",
       "4     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hvl4Hst065u"
   },
   "source": [
    "\n",
    "## 2. Model specific data preparation (tensorflow)\n",
    "## a) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts0H5owM065v"
   },
   "outputs": [],
   "source": [
    "x_train_pt = torch.from_numpy(train_images.values.reshape((-1, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "kfpc1P3A065v",
    "outputId": "80d6f98b-d54a-48d8-ba78-d831ad780955"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use random seed to create fake input data\n",
    "seed = torch.rand((28,28))\n",
    "seed_im = seed.numpy() * 255\n",
    "plt.figure()\n",
    "plt.imshow(seed_im, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAjl91Lm065v"
   },
   "source": [
    "### b) Tensor view of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR0SONiS065w",
    "outputId": "2baea354-4418-4611-b646-a4c6bb53de38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 237,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xx2B52_n065w",
    "outputId": "f679b820-b0a9-46ae-b8c1-61ef6f3ed8f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 209,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d-1O3ac065w",
    "outputId": "45f7af07-88b2-4b2b-829c-74f770d25917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.9882, 0.9176, 0.9333,\n",
       "        0.8784, 0.8431, 0.8431, 0.8980, 0.4235, 0.7059, 0.8118, 0.8392, 0.8784,\n",
       "        0.9059, 0.9765, 0.9961, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pt[0][0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeUJVqsI065x"
   },
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsQu8jb2065x"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "      nn.init.uniform_(m.weight.data, -1,1)\n",
    "      nn.init.zeros_(m.bias.data)\n",
    "  if isinstance(m, nn.Conv2d):\n",
    "      nn.init.uniform_(m.weight.data, 0.0, 0.02)\n",
    "      nn.init.zeros_(m.bias.data)\n",
    "  if isinstance(m, nn.ConvTranspose2d):\n",
    "      nn.init.uniform_(m.weight.data, 0.0, 0.02)\n",
    "      nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4KeOa9K065y"
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, channels, height, width):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = (channels, height, width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUFkLr4M065y"
   },
   "source": [
    "### a.1) Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQ9ReExW065z"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = nn.Sequential()\n",
    "    model.add_module(\"Conv2D1\", nn.ConvTranspose2d(100, 64, 7, stride=1, padding=0, bias=True))\n",
    "    #model.add_module(\"Reshape\", Reshape(64, 7, 7))\n",
    "    model.add_module(\"Batchnorm1\", nn.BatchNorm2d(64))\n",
    "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Conv2D2\", nn.ConvTranspose2d(64, 32, (8,8), stride=(1,1), padding=0, bias=True))\n",
    "    model.add_module(\"Batchnorm2\", nn.BatchNorm2d(32))\n",
    "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Conv2D3\", nn.ConvTranspose2d(32, 1, (15,15), stride=1, padding=0, bias=True))\n",
    "    model.add_module(\"Batchnorm3\", nn.BatchNorm2d(1))\n",
    "    model.add_module(\"Sigmoid1\", nn.Sigmoid())\n",
    "    return model\n",
    "generator = generator_model()\n",
    "#generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBZJiTRZ065z",
    "outputId": "88b33ddb-4957-41cb-8ae8-730eeeacd402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 214,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated image not trained\n",
    "fake_im_not_trained = generator(torch.rand([1, 100, 1, 1]))\n",
    "# check output shape of generator\n",
    "fake_im_not_trained.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7tqK5yB0650"
   },
   "source": [
    "###  a.2) Inspect the generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoiTZ37X0650",
    "outputId": "47590bb6-5177-4841-8e0b-ab66fac7e2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
      "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
      "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
      "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (Sigmoid1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0v3fU5j0650",
    "outputId": "da8c0357-f1a7-41c8-e88c-2bc98bfafa1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
       "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
       "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (Sigmoid1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 240,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfrxvvCj0651"
   },
   "source": [
    "### a.3) Inspect the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yKD8kav0651",
    "outputId": "c5183d4a-aa4a-4fc4-a185-9768d8247590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.8387e-03, 8.6164e-03, 6.0610e-04,  ..., 1.3265e-02,\n",
       "          1.4458e-02, 2.3743e-03],\n",
       "         [1.2968e-02, 4.2289e-03, 4.4110e-03,  ..., 1.9888e-02,\n",
       "          1.6134e-02, 1.3053e-02],\n",
       "         [4.3992e-03, 1.8454e-02, 1.2182e-02,  ..., 2.0308e-03,\n",
       "          1.3722e-02, 1.0236e-02],\n",
       "         ...,\n",
       "         [6.9508e-04, 7.8283e-03, 8.6484e-03,  ..., 1.7467e-02,\n",
       "          5.9848e-03, 1.7399e-02],\n",
       "         [9.6221e-03, 3.1835e-03, 1.4939e-03,  ..., 1.8103e-02,\n",
       "          1.4614e-02, 7.5020e-03],\n",
       "         [1.8515e-03, 1.3184e-02, 5.1207e-03,  ..., 1.3146e-02,\n",
       "          1.1817e-02, 8.5925e-03]],\n",
       "\n",
       "        [[1.3741e-02, 1.6397e-02, 6.7561e-04,  ..., 1.4314e-02,\n",
       "          4.5961e-03, 1.3329e-02],\n",
       "         [8.8794e-03, 3.6732e-03, 7.4269e-03,  ..., 1.1056e-02,\n",
       "          1.9620e-02, 4.9329e-05],\n",
       "         [1.9194e-02, 1.6131e-02, 8.2811e-03,  ..., 9.1697e-03,\n",
       "          9.0593e-03, 4.9672e-03],\n",
       "         ...,\n",
       "         [4.0603e-03, 1.2944e-03, 1.0292e-02,  ..., 1.2466e-02,\n",
       "          1.9557e-02, 6.3041e-03],\n",
       "         [1.0399e-03, 1.9068e-03, 1.6229e-02,  ..., 1.7395e-02,\n",
       "          7.1944e-03, 9.9271e-03],\n",
       "         [1.7100e-02, 9.9046e-03, 1.3948e-02,  ..., 1.5654e-02,\n",
       "          2.3403e-03, 9.9671e-03]],\n",
       "\n",
       "        [[1.4480e-02, 5.9755e-03, 1.1942e-02,  ..., 4.9440e-03,\n",
       "          1.6997e-02, 2.5014e-03],\n",
       "         [3.9179e-03, 1.3048e-03, 6.6009e-03,  ..., 9.6336e-03,\n",
       "          1.6332e-02, 1.1183e-02],\n",
       "         [3.1325e-04, 5.3933e-03, 5.3007e-03,  ..., 1.1008e-02,\n",
       "          1.8668e-02, 1.4931e-02],\n",
       "         ...,\n",
       "         [1.3777e-02, 7.4203e-03, 2.0713e-03,  ..., 6.0385e-03,\n",
       "          1.9857e-02, 1.5705e-02],\n",
       "         [3.4177e-04, 2.6488e-03, 1.3881e-02,  ..., 6.1788e-03,\n",
       "          1.6782e-02, 1.1038e-02],\n",
       "         [1.4779e-03, 1.4386e-02, 1.0825e-02,  ..., 7.6533e-03,\n",
       "          5.0537e-03, 6.1793e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.8755e-02, 9.3769e-03, 1.3709e-02,  ..., 1.4130e-02,\n",
       "          1.3750e-03, 8.6898e-03],\n",
       "         [1.8342e-02, 7.0055e-03, 1.8252e-02,  ..., 1.8204e-02,\n",
       "          8.0852e-03, 7.2293e-03],\n",
       "         [9.1804e-03, 3.0332e-03, 4.2933e-04,  ..., 4.1339e-03,\n",
       "          5.5297e-03, 1.0974e-02],\n",
       "         ...,\n",
       "         [1.6234e-02, 1.4217e-03, 1.1382e-02,  ..., 4.2932e-03,\n",
       "          2.2458e-03, 1.4716e-02],\n",
       "         [5.4945e-03, 6.1258e-03, 1.4298e-02,  ..., 1.2340e-02,\n",
       "          6.5794e-03, 7.4028e-04],\n",
       "         [1.2502e-03, 7.3687e-03, 7.5093e-03,  ..., 1.9002e-03,\n",
       "          1.2728e-02, 8.0734e-03]],\n",
       "\n",
       "        [[3.1843e-04, 9.2718e-03, 1.1880e-02,  ..., 6.4162e-03,\n",
       "          4.9884e-03, 2.5991e-03],\n",
       "         [1.8664e-02, 7.2598e-04, 1.1506e-02,  ..., 1.9937e-03,\n",
       "          1.5923e-02, 1.2768e-02],\n",
       "         [1.3506e-02, 3.0085e-03, 2.8026e-03,  ..., 1.5796e-02,\n",
       "          6.4924e-03, 1.8808e-02],\n",
       "         ...,\n",
       "         [1.3417e-02, 5.8373e-03, 2.8725e-03,  ..., 2.3989e-03,\n",
       "          1.5043e-02, 4.8076e-03],\n",
       "         [2.1877e-03, 1.0137e-02, 1.4781e-02,  ..., 1.2044e-02,\n",
       "          3.3425e-03, 9.2195e-03],\n",
       "         [6.6169e-03, 1.0307e-02, 1.9783e-02,  ..., 1.0865e-02,\n",
       "          3.6493e-03, 7.2774e-03]],\n",
       "\n",
       "        [[1.4588e-02, 1.1167e-02, 3.9304e-03,  ..., 8.4826e-03,\n",
       "          8.5981e-03, 2.8496e-03],\n",
       "         [9.4010e-03, 1.4168e-02, 1.7817e-02,  ..., 1.0172e-02,\n",
       "          1.2879e-02, 1.3685e-03],\n",
       "         [4.5755e-04, 1.0310e-02, 1.4719e-02,  ..., 5.4737e-03,\n",
       "          7.6705e-04, 1.9869e-02],\n",
       "         ...,\n",
       "         [1.5080e-03, 1.7872e-02, 3.1504e-03,  ..., 2.1744e-03,\n",
       "          1.6883e-02, 1.4555e-02],\n",
       "         [1.7941e-02, 1.5973e-02, 3.7245e-03,  ..., 1.6000e-02,\n",
       "          8.1679e-03, 1.5642e-02],\n",
       "         [1.1774e-02, 1.2114e-02, 1.4508e-03,  ..., 1.9303e-02,\n",
       "          1.7789e-02, 1.9168e-02]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 241,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sln7_yqA0651",
    "outputId": "3953f8a8-1283-4d47-a3e6-e6d8ede3b769"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 7, 7])"
      ]
     },
     "execution_count": 218,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJMFFTGQ0651",
    "outputId": "50b49db7-1ef9-465e-9389-98caf84bae74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 219,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxJ6gVze0653",
    "outputId": "b5a05f6c-17fe-4927-997b-c71adcd8cfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0].bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohr9EW-y0654"
   },
   "source": [
    "### b.1) Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGDLcmK00654"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = nn.Sequential()\n",
    "    model.add_module(\"Conv2D1\", nn.Conv2d(1, 2, kernel_size=5, stride=1, padding=2))\n",
    "    model.add_module(\"Pooling1\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
    "    model.add_module(\"Dropout1\", nn.Dropout(0.3))\n",
    "    \n",
    "    model.add_module(\"Conv2D2\", nn.Conv2d(2, 2, kernel_size=5, stride=1, padding=2))\n",
    "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Conv2D3\", nn.Conv2d(2, 1, kernel_size=5, stride=1, padding=0))\n",
    "    model.add_module(\"LeakyRelu3\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Flatten1\", nn.Flatten())\n",
    "    \n",
    "    model.add_module(\"Dense1\", nn.Linear(100,100))\n",
    "    model.add_module(\"LeakyRelu4\", nn.LeakyReLU())\n",
    "    \n",
    "    model.add_module(\"Dense2\", nn.Linear(100,64))\n",
    "    model.add_module(\"Tanh\", nn.Tanh())\n",
    "    \n",
    "    model.add_module(\"Dense3\", nn.Linear(64,1))\n",
    "    model.add_module(\"Sigmoid\", nn.Sigmoid())\n",
    "    return model\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eGFfyYO0655"
   },
   "source": [
    "### b.2) Inspect the discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqwNgL5J0655",
    "outputId": "394bdd68-8863-46f1-be11-70955b8455de",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
      "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
      "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
      "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
      "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (Tanh): Tanh()\n",
      "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (Sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4763]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(discriminator)\n",
    "discriminator(fake_im_not_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTX4zp9c0655",
    "outputId": "85307e84-6a4d-4b5b-d2d3-0a56a97fc39d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
       "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
       "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
       "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (Tanh): Tanh()\n",
       "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U8TOF5r0655"
   },
   "source": [
    "### b.3) Inspect the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4yXCZgM80656",
    "outputId": "a32b574e-93a3-417f-be81-2e0431867e6a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 224,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].weight[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCKCE5rX0656",
    "outputId": "b581429a-d0b0-471c-ee73-528d64d78033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u4FdvnE0657",
    "outputId": "7c3f9b44-0eaf-4ecc-8d76-13e0ead29eb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 226,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkFVYDoT0657",
    "outputId": "d18b394a-fc80-48b2-e9d3-be500f816a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 227,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator[0].bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Itee_8M0657"
   },
   "source": [
    "## 4. Loss & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQrC1KNF0658"
   },
   "source": [
    "### 4.a) Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUJbFTAz0658"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.BCEWithLogitsLoss()\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(torch.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzHIkuZM0658"
   },
   "source": [
    "### 4.b) Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDIX2a000659"
   },
   "outputs": [],
   "source": [
    "def real_discriminator_loss(real_output):\n",
    "    return  cross_entropy(torch.ones_like(real_output), real_output)\n",
    "\n",
    "def fake_discriminator_loss(fake_output):\n",
    "    return cross_entropy(torch.zeros_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7hrseRk0659"
   },
   "source": [
    "## 4.c) Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hic_TlMX0659"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = optim.Adam(generator.parameters(), lr=1e-2)\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-2)\n",
    "\n",
    "def correct_classification(y_true, y_prob):\n",
    "    assert y_true.size() == y_prob.size()\n",
    "    y_prob = (y_prob > 0.5).float()\n",
    "    return (y_true == y_prob).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYLo8yIj0659"
   },
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs8u8LUz065-"
   },
   "outputs": [],
   "source": [
    "# This annotation causes the function to be \"compiled\".\n",
    "#@tf.function\n",
    "def train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size = 100):\n",
    "    gen_loss_tot = []\n",
    "    disc_loss_tot = []\n",
    "    disc_acc_real_tot = 0\n",
    "    disc_acc_fake_tot = 0\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    for beg_i in range(0, x_train_pt.shape[0], batch_size):\n",
    "        x_train_batch_pt = x_train_pt[beg_i:beg_i + batch_size]\n",
    "\n",
    "        x_fake_batch_pt = torch.rand([batch_size, 100, 1, 1])\n",
    "        \n",
    "        discriminator_optimizer.zero_grad()\n",
    "        real_output = discriminator(x_train_batch_pt.float()).view(-1)\n",
    "        disc_loss_real = real_discriminator_loss(real_output)\n",
    "        disc_loss_real.backward()\n",
    "        \n",
    "        generated_images = generator(x_fake_batch_pt)\n",
    "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
    "        disc_loss_fake = fake_discriminator_loss(fake_output)\n",
    "        disc_loss_fake.backward()\n",
    "        err = disc_loss_fake + disc_loss_real\n",
    "        discriminator_optimizer.step()\n",
    "        \n",
    "        # optimize generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        gen_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        gen_loss_tot.append(gen_loss.mean().item())\n",
    "        disc_loss_tot.append(err.mean().item())\n",
    "        disc_acc_real_tot += correct_classification(torch.ones_like(real_output), real_output)\n",
    "        disc_acc_fake_tot += correct_classification(torch.zeros_like(fake_output), fake_output)\n",
    "\n",
    "    disc_acc_real_tot = disc_acc_real_tot/x_train_pt.size(0)\n",
    "    disc_acc_fake_tot = disc_acc_fake_tot/x_train_pt.size(0)\n",
    "    print([disc_acc_real_tot, disc_acc_fake_tot])\n",
    "    disc_acc_tot = np.mean([disc_acc_real_tot, disc_acc_fake_tot])\n",
    "    return gen_loss_tot, disc_loss_tot, disc_acc_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "F-ILomMn065-",
    "outputId": "06dae2b4-4755-4cdb-dec5-6e564594ea97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9985, 0.0]\n",
      "Epoch 1, Loss_Generator: 0.3137556545933088, Loss_Discriminator: 1.0079493055740991, Discriminator_Accuracy: 49.925000000000004\n",
      "[1.0, 0.0]\n",
      "Epoch 2, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 3, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 4, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 5, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 6, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n",
      "[1.0, 0.0]\n",
      "Epoch 7, Loss_Generator: 0.31326165795326233, Loss_Discriminator: 1.0064088106155396, Discriminator_Accuracy: 50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-018828624942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-1cc16055fa9a>\u001b[0m in \u001b[0;36mtrain_step_pt\u001b[0;34m(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake_batch_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdisc_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_discriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdisc_loss_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses_generator_pt = []\n",
    "train_losses_discriminator_pt = []\n",
    "train_acc_discriminator_pt = []\n",
    "epochs = 15\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    gen_loss, disc_loss, disc_acc = train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
    "    gen_loss = np.mean(gen_loss)\n",
    "    disc_loss = np.mean(disc_loss)\n",
    "    train_losses_generator_pt.append(gen_loss)\n",
    "    train_losses_discriminator_pt.append(disc_loss)\n",
    "    train_acc_discriminator_pt.append(disc_acc*100)\n",
    "\n",
    "\n",
    "    template = (\"Epoch {}, Loss_Generator: {}, Loss_Discriminator: {}, Discriminator_Accuracy: {}\")\n",
    "    print(template.format(epoch+1, gen_loss, disc_loss, disc_acc*100))\n",
    "end = time.time()\n",
    "print(f\"Total training time{(end - start)/60.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGOH030LKOwE"
   },
   "outputs": [],
   "source": [
    "print(f\"Total training time{(end - start)/60.0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E88Mbb_M065-"
   },
   "source": [
    "### b) Training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8-7QBvL065_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(train_acc_discriminator_pt)\n",
    "plt.title('discriminator accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['discriminator_train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG8W0zvk065_"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(train_losses_generator_pt)\n",
    "plt.plot(train_losses_discriminator_pt)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['generator', 'discriminator'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UiwHcmI4C_d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdVnypYA065_"
   },
   "source": [
    "### c1) Generator output before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMDDynAD066A"
   },
   "outputs": [],
   "source": [
    "fake_im_not_trained = fake_im_not_trained.detach().numpy() * 255\n",
    "fake_im_not_trained = fake_im_not_trained.reshape((28,28))\n",
    "plt.figure()\n",
    "plt.imshow(fake_im_not_trained, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH3KjkI-066A"
   },
   "source": [
    "### c2) Generator output after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfqPBgZo066A"
   },
   "outputs": [],
   "source": [
    "seed2 = torch.rand([1, 100, 1, 1])\n",
    "generator.train(False)\n",
    "fake_im = generator(seed2)\n",
    "fake_im = fake_im.detach().numpy() * 255\n",
    "fake_im = fake_im.reshape((28,28))\n",
    "plt.figure()\n",
    "plt.imshow(fake_im, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References\n",
    "The presented model is based on a combination of two tutorials for deep cnn-gans:\n",
    "1) https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "\n",
    "2) https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "cnngan_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
