{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "cnngan_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QAjl91Lm065v",
        "UUFkLr4M065y",
        "I7tqK5yB0650",
        "zfrxvvCj0651",
        "ohr9EW-y0654",
        "-eGFfyYO0655",
        "8U8TOF5r0655",
        "sQrC1KNF0658",
        "E88Mbb_M065-",
        "rdVnypYA065_",
        "RH3KjkI-066A"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/blob/master/cnngan_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVotrWM-065f"
      },
      "source": [
        "# Implementing a CNNGAN with pytroch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt9oTYk6065n"
      },
      "source": [
        "## 1. Import and Preprocessing\n",
        "### a) Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOvHT87j065o"
      },
      "source": [
        "# Load required packages - data handling & plotting\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Load required packages - deep learning \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2kizsA7065p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e523e8ae-72d4-403a-c0e6-434f518e1a1f"
      },
      "source": [
        "print(f\"tensorflow: {torch.__version__}\")\n",
        "import sys\n",
        "print(f\"python: {sys.version[:5]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow: 1.8.1+cu101\n",
            "python: 3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7um10LNJ065q"
      },
      "source": [
        "### b) Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9K_QRXq065r"
      },
      "source": [
        "#download and save to file\n",
        "#urllib.request.urlretrieve(\n",
        "#    \"https://media.githubusercontent.com/media/mmeierer/CNN---TensorFlow-vs-PyTorch/main/fashion-mnist_train.csv\",\n",
        "#    \"fashion-mnist_train2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOi4NVI065r"
      },
      "source": [
        "train_data = pd.read_csv('https://media.githubusercontent.com/media/PaprikaSteiger/CNN_GAN_tensorflow_vs_pytorch/master/fashion-mnist_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukf4AIqY065r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "d42b6c6b-2b8e-44ae-f143-ba4146cdd243"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>211</td>\n",
              "      <td>220</td>\n",
              "      <td>214</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>222</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>214</td>\n",
              "      <td>163</td>\n",
              "      <td>146</td>\n",
              "      <td>165</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>183</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>102</td>\n",
              "      <td>165</td>\n",
              "      <td>160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>163</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>249</td>\n",
              "      <td>207</td>\n",
              "      <td>197</td>\n",
              "      <td>202</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>69</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>136</td>\n",
              "      <td>147</td>\n",
              "      <td>144</td>\n",
              "      <td>121</td>\n",
              "      <td>102</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "2      6       0       0       0  ...         0         0         0         0\n",
              "3      0       0       0       0  ...         0         0         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqXVdux_065s"
      },
      "source": [
        "train_images = train_data.iloc[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54zxTjsL065s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ea855e0a-9bb3-4224-9414-8247064757f8"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images.values[0].reshape(28,28), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDAY2krK065t"
      },
      "source": [
        "### c) Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0M8L-K065t"
      },
      "source": [
        "# use maximum normalization\n",
        "train_images = train_images / np.float32(255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msQ_biny065u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "6261fb75-ad67-4488-995d-d74b83214d44"
      },
      "source": [
        "train_images.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>pixel40</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.360784</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.419608</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.890196</td>\n",
              "      <td>...</td>\n",
              "      <td>0.827451</td>\n",
              "      <td>0.862745</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.749020</td>\n",
              "      <td>0.839216</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.717647</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.976471</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.772549</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086275</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180392</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082353</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.741176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.901961</td>\n",
              "      <td>0.929412</td>\n",
              "      <td>0.898039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.454902</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3    pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "1     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "2     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "3     0.0     0.0     0.0  0.003922  ...       0.0       0.0       0.0       0.0\n",
              "4     0.0     0.0     0.0  0.000000  ...       0.0       0.0       0.0       0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hvl4Hst065u"
      },
      "source": [
        "\n",
        "## 2. Model specific data preparation (tensorflow)\n",
        "## a) Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts0H5owM065v"
      },
      "source": [
        "x_train_pt = torch.from_numpy(train_images.values.reshape((-1, 1, 28, 28)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfpc1P3A065v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7a77bc46-750b-44dd-ec2d-65327aa82075"
      },
      "source": [
        "# use random seed to create fake input data\n",
        "seed = torch.rand((28,28))\n",
        "seed_im = seed.numpy() * 255\n",
        "plt.figure()\n",
        "plt.imshow(seed_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAjl91Lm065v"
      },
      "source": [
        "### b) Tensor view of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR0SONiS065w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264a7fb5-eba3-4070-d634-e5fccbf2db09"
      },
      "source": [
        "x_train_pt.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx2B52_n065w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bbcce2-c14e-4c06-dc2e-d29aa20d8da3"
      },
      "source": [
        "seed.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d-1O3ac065w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3206a458-6548-4e59-98bb-66fc32a4410a"
      },
      "source": [
        "x_train_pt[0][0][5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.9882, 0.9176, 0.9333,\n",
              "        0.8784, 0.8431, 0.8431, 0.8980, 0.4235, 0.7059, 0.8118, 0.8392, 0.8784,\n",
              "        0.9059, 0.9765, 0.9961, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUJVqsI065x"
      },
      "source": [
        "## 3. Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsQu8jb2065x"
      },
      "source": [
        "def weights_init(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "      nn.init.uniform_(m.weight.data, -1,1)\n",
        "      nn.init.zeros_(m.bias.data)\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "      nn.init.zeros_(m.bias.data)\n",
        "  if isinstance(m, nn.ConvTranspose2d):\n",
        "      nn.init.zeros_(m.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4KeOa9K065y"
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, channels, height, width):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = (channels, height, width)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUFkLr4M065y"
      },
      "source": [
        "### a.1) Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ9ReExW065z"
      },
      "source": [
        "def generator_model():\n",
        "    model = nn.Sequential()\n",
        "    model.add_module(\"Conv2D1\", nn.ConvTranspose2d(100, 64, 7, stride=1, padding=0, bias=True))\n",
        "    #model.add_module(\"Reshape\", Reshape(64, 7, 7))\n",
        "    model.add_module(\"Batchnorm1\", nn.BatchNorm2d(64))\n",
        "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D2\", nn.ConvTranspose2d(64, 32, (8,8), stride=(1,1), padding=0, bias=True))\n",
        "    model.add_module(\"Batchnorm2\", nn.BatchNorm2d(32))\n",
        "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D3\", nn.ConvTranspose2d(32, 1, (15,15), stride=1, padding=0, bias=True))\n",
        "    model.add_module(\"Batchnorm3\", nn.BatchNorm2d(1))\n",
        "    model.add_module(\"Sigmoid1\", nn.Sigmoid())\n",
        "    return model\n",
        "generator = generator_model()\n",
        "#generator.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBZJiTRZ065z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb202b0-8ff2-4572-90c8-1ecc9c312a44"
      },
      "source": [
        "# generated image not trained\n",
        "fake_im_not_trained = generator(torch.rand([1, 100, 1, 1]))\n",
        "# check output shape of generator\n",
        "fake_im_not_trained.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7tqK5yB0650"
      },
      "source": [
        "###  a.2) Inspect the generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoiTZ37X0650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868902ce-e513-4c9e-c2a4-3da7dc4f405c"
      },
      "source": [
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
            "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
            "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Sigmoid1): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0v3fU5j0650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6b1b2f-7ec9-49ee-d7f1-3a7dadecf840"
      },
      "source": [
        "generator.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv2D1): ConvTranspose2d(100, 64, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (Batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D2): ConvTranspose2d(64, 32, kernel_size=(8, 8), stride=(1, 1))\n",
              "  (Batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D3): ConvTranspose2d(32, 1, kernel_size=(15, 15), stride=(1, 1))\n",
              "  (Batchnorm3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (Sigmoid1): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfrxvvCj0651"
      },
      "source": [
        "### a.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yKD8kav0651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b72ecd-fb8e-46c5-d9e3-66fad0d3993f"
      },
      "source": [
        "generator[0].weight[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 6.3130e-03, -6.7919e-05, -2.1170e-03,  ...,  2.1251e-03,\n",
              "          -5.0520e-03, -1.5231e-03],\n",
              "         [-9.0585e-03, -1.1715e-02,  3.5456e-03,  ..., -1.2342e-02,\n",
              "          -1.0965e-02, -5.8234e-03],\n",
              "         [-1.4962e-02, -1.4695e-02,  3.9525e-04,  ...,  1.6727e-03,\n",
              "          -1.5103e-02, -3.6423e-05],\n",
              "         ...,\n",
              "         [-1.2250e-02, -1.4128e-02, -1.0528e-02,  ..., -5.0528e-03,\n",
              "          -4.8742e-03, -1.0359e-02],\n",
              "         [ 5.0019e-03, -4.8016e-03, -8.3056e-04,  ..., -1.4288e-03,\n",
              "           6.0208e-03,  6.8910e-03],\n",
              "         [-1.0063e-02,  1.0134e-03,  1.6147e-02,  ...,  1.0967e-02,\n",
              "           7.2760e-03, -1.5149e-02]],\n",
              "\n",
              "        [[ 5.6515e-03, -4.4763e-03, -1.2783e-02,  ...,  1.7256e-02,\n",
              "           4.3931e-04, -1.4256e-02],\n",
              "         [ 9.5881e-03, -1.7662e-03, -1.5098e-02,  ..., -2.8831e-03,\n",
              "           3.7537e-03, -4.1208e-04],\n",
              "         [ 1.6675e-02, -1.7152e-02,  1.1208e-02,  ...,  1.9591e-03,\n",
              "           1.7835e-02, -6.0870e-03],\n",
              "         ...,\n",
              "         [-2.3545e-03,  6.7891e-04,  2.1731e-04,  ...,  1.6833e-02,\n",
              "          -1.0151e-02,  1.4716e-02],\n",
              "         [-1.6714e-03, -5.3929e-03, -1.1948e-02,  ...,  1.2322e-02,\n",
              "          -1.5956e-02, -6.0427e-03],\n",
              "         [-1.7202e-02,  1.5833e-02, -8.6828e-03,  ...,  3.2664e-03,\n",
              "          -1.2991e-02, -1.0538e-02]],\n",
              "\n",
              "        [[-2.9360e-03,  1.4068e-02,  1.4008e-02,  ...,  9.3948e-03,\n",
              "           5.4022e-03,  1.5318e-02],\n",
              "         [-1.4778e-02,  8.4849e-03,  1.1482e-02,  ..., -1.3863e-03,\n",
              "           8.0235e-04, -1.7302e-02],\n",
              "         [ 5.4448e-03,  1.1762e-02,  5.4655e-03,  ..., -6.9631e-03,\n",
              "           4.9286e-03, -9.6462e-03],\n",
              "         ...,\n",
              "         [-1.4524e-02,  3.6302e-03,  1.5437e-02,  ...,  1.7149e-02,\n",
              "           1.0186e-02, -1.2926e-02],\n",
              "         [-4.2275e-03, -9.7644e-03,  3.2031e-03,  ...,  8.5497e-03,\n",
              "           5.5207e-03,  6.1149e-03],\n",
              "         [-1.2672e-02, -8.9523e-03, -1.7626e-02,  ..., -1.0870e-02,\n",
              "           2.6920e-04, -1.7851e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.1639e-02, -9.5610e-03,  4.2663e-03,  ...,  1.2966e-03,\n",
              "           1.3987e-03,  1.1052e-02],\n",
              "         [-8.6663e-03,  1.5415e-02,  1.1933e-02,  ..., -8.5288e-03,\n",
              "          -4.5105e-03,  1.5143e-02],\n",
              "         [-1.1729e-02, -1.4704e-03,  1.7066e-02,  ...,  9.4317e-03,\n",
              "          -3.8775e-03, -3.2227e-03],\n",
              "         ...,\n",
              "         [-1.4797e-02,  3.6033e-03, -9.3196e-03,  ..., -1.5187e-02,\n",
              "          -1.1293e-02, -1.3480e-03],\n",
              "         [ 8.4099e-03, -1.0451e-03, -8.0286e-03,  ...,  1.5611e-02,\n",
              "           4.1362e-04,  1.7574e-02],\n",
              "         [-3.3289e-03, -7.5091e-03, -4.9130e-03,  ..., -1.2339e-03,\n",
              "           1.9471e-03, -2.3425e-03]],\n",
              "\n",
              "        [[-9.5574e-03, -1.5490e-02,  2.2667e-03,  ..., -8.3266e-03,\n",
              "           1.2148e-02,  3.5141e-03],\n",
              "         [ 7.7948e-03, -9.3484e-03,  1.4731e-02,  ...,  3.3813e-03,\n",
              "          -1.0321e-02, -7.8533e-03],\n",
              "         [-1.7808e-03, -1.2644e-02, -1.5850e-02,  ..., -5.6617e-03,\n",
              "           1.7777e-02, -1.4794e-02],\n",
              "         ...,\n",
              "         [ 6.2523e-04, -1.1431e-02, -1.2705e-02,  ...,  7.7808e-03,\n",
              "           4.0299e-03, -4.7284e-03],\n",
              "         [-9.0248e-04,  3.4553e-03,  2.6049e-03,  ..., -5.2689e-03,\n",
              "          -9.8261e-04, -4.4486e-03],\n",
              "         [ 8.1264e-03,  1.5748e-02,  8.4137e-03,  ...,  8.2411e-03,\n",
              "           1.3293e-02,  9.5272e-04]],\n",
              "\n",
              "        [[ 2.9522e-03,  1.4406e-02, -6.0873e-03,  ...,  5.8622e-03,\n",
              "           1.2868e-02, -1.0098e-03],\n",
              "         [ 1.4376e-02,  4.1596e-04,  4.8386e-03,  ..., -1.7052e-02,\n",
              "           1.0921e-02,  1.4846e-02],\n",
              "         [-1.6261e-02,  8.7537e-03, -4.6332e-03,  ...,  1.3109e-02,\n",
              "           6.4963e-03, -1.5946e-02],\n",
              "         ...,\n",
              "         [ 8.0521e-03, -1.3180e-02, -6.3231e-03,  ...,  1.4274e-03,\n",
              "           9.8137e-03,  9.6466e-03],\n",
              "         [ 1.4506e-02, -1.0850e-02,  1.3305e-02,  ..., -1.5741e-02,\n",
              "          -7.5927e-03, -7.7823e-03],\n",
              "         [ 3.0766e-04,  3.4761e-03,  5.2787e-03,  ...,  9.2742e-03,\n",
              "           1.3960e-02,  1.2724e-02]]], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sln7_yqA0651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de33086-d41c-4dcc-fcfc-4412973ea52c"
      },
      "source": [
        "generator[0].weight.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 64, 7, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMFFTGQ0651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80699ee5-d7da-4c0f-f8a7-0759fb244d3b"
      },
      "source": [
        "generator[0].bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxJ6gVze0653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9920f497-3e6b-4935-809d-baaca5476d20"
      },
      "source": [
        "generator[0].bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohr9EW-y0654"
      },
      "source": [
        "### b.1) Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGDLcmK00654"
      },
      "source": [
        "def discriminator_model():\n",
        "    model = nn.Sequential()\n",
        "    model.add_module(\"Conv2D1\", nn.Conv2d(1, 2, kernel_size=5, stride=1, padding=2))\n",
        "    model.add_module(\"Pooling1\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "    model.add_module(\"LeakyRelu1\", nn.LeakyReLU())\n",
        "    model.add_module(\"Dropout1\", nn.Dropout(0.3))\n",
        "    \n",
        "    model.add_module(\"Conv2D2\", nn.Conv2d(2, 2, kernel_size=5, stride=1, padding=2))\n",
        "    model.add_module(\"LeakyRelu2\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Conv2D3\", nn.Conv2d(2, 1, kernel_size=5, stride=1, padding=0))\n",
        "    model.add_module(\"LeakyRelu3\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Flatten1\", nn.Flatten())\n",
        "    \n",
        "    model.add_module(\"Dense1\", nn.Linear(100,100))\n",
        "    model.add_module(\"LeakyRelu4\", nn.LeakyReLU())\n",
        "    \n",
        "    model.add_module(\"Dense2\", nn.Linear(100,64))\n",
        "    model.add_module(\"Tanh\", nn.Tanh())\n",
        "    \n",
        "    model.add_module(\"Dense3\", nn.Linear(64,1))\n",
        "    model.add_module(\"Sigmoid\", nn.Sigmoid())\n",
        "    return model\n",
        "discriminator = discriminator_model()\n",
        "#discriminator = discriminator.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eGFfyYO0655"
      },
      "source": [
        "### b.2) Inspect the discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fqwNgL5J0655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4ea6c4-253b-4594-c065-6f3eca78a841"
      },
      "source": [
        "print(discriminator)\n",
        "discriminator(fake_im_not_trained)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
            "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
            "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
            "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
            "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
            "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (Tanh): Tanh()\n",
            "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (Sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5184]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTX4zp9c0655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a081573a-2678-4d5f-a10d-8a0ce1ccdc77"
      },
      "source": [
        "discriminator.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv2D1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Pooling1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (LeakyRelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (Dropout1): Dropout(p=0.3, inplace=False)\n",
              "  (Conv2D2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (LeakyRelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (Conv2D3): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (LeakyRelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (Flatten1): Flatten(start_dim=1, end_dim=-1)\n",
              "  (Dense1): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (LeakyRelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (Dense2): Linear(in_features=100, out_features=64, bias=True)\n",
              "  (Tanh): Tanh()\n",
              "  (Dense3): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (Sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U8TOF5r0655"
      },
      "source": [
        "### b.3) Inspect the first convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yXCZgM80656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16721e3-3f29-4b13-cd18-71e711a2beff"
      },
      "source": [
        "discriminator[0].weight[0].type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCKCE5rX0656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85331f7c-758f-4966-8c72-3914bf23ab3c"
      },
      "source": [
        "discriminator[0].weight.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u4FdvnE0657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200f945e-186e-4851-efb1-313b42564112"
      },
      "source": [
        "discriminator[0].bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFVYDoT0657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d52d4f5-b899-4f83-9e29-3f9f9b23e056"
      },
      "source": [
        "discriminator[0].bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Itee_8M0657"
      },
      "source": [
        "## 4. Loss & Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQrC1KNF0658"
      },
      "source": [
        "### 4.a) Generator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJbFTAz0658"
      },
      "source": [
        "cross_entropy = nn.BCEWithLogitsLoss()\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(torch.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzHIkuZM0658"
      },
      "source": [
        "### 4.b) Discriminator loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDIX2a000659"
      },
      "source": [
        "def real_discriminator_loss(real_output):\n",
        "    return  cross_entropy(torch.ones_like(real_output), real_output)\n",
        "\n",
        "def fake_discriminator_loss(fake_output):\n",
        "    return cross_entropy(torch.zeros_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7hrseRk0659"
      },
      "source": [
        "## 4.c) Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hic_TlMX0659"
      },
      "source": [
        "generator_optimizer = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-3)\n",
        "\n",
        "#train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy') # only for discriminator\n",
        "\n",
        "def correct_classification(y_true, y_prob):\n",
        "    assert y_true.size() == y_prob.size()\n",
        "    y_prob = (y_prob > 0.5).float()\n",
        "    return (y_true == y_prob).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYLo8yIj0659"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs8u8LUz065-"
      },
      "source": [
        "# This annotation causes the function to be \"compiled\".\n",
        "#@tf.function\n",
        "def train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size = 100):\n",
        "    gen_loss_tot = []\n",
        "    disc_loss_tot = []\n",
        "    disc_acc_real_tot = 0\n",
        "    disc_acc_fake_tot = 0\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    for beg_i in range(0, x_train_pt.shape[0], batch_size):\n",
        "        x_train_batch_pt = x_train_pt[beg_i:beg_i + batch_size]\n",
        "\n",
        "        x_fake_batch_pt = torch.rand([batch_size, 100, 1, 1])\n",
        "        \n",
        "        discriminator_optimizer.zero_grad()\n",
        "        real_output = discriminator(x_train_batch_pt.float()).view(-1)\n",
        "        disc_loss_real = real_discriminator_loss(real_output)\n",
        "        disc_loss_real.backward()\n",
        "        \n",
        "        generated_images = generator(x_fake_batch_pt)\n",
        "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
        "        disc_loss_fake = fake_discriminator_loss(fake_output)\n",
        "        disc_loss_fake.backward()\n",
        "        err = disc_loss_fake + disc_loss_real\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        \n",
        "        # optimize generator\n",
        "        generator_optimizer.zero_grad()\n",
        "        fake_output = discriminator(generated_images.detach()).view(-1)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        gen_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "        \n",
        "        gen_loss_tot.append(gen_loss.mean().item())\n",
        "        disc_loss_tot.append(err.mean().item())\n",
        "        disc_acc_real_tot += correct_classification(torch.ones_like(real_output), real_output)\n",
        "        disc_acc_fake_tot += correct_classification(torch.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    disc_acc_real_tot = disc_acc_real_tot/x_train_pt.size(0)\n",
        "    disc_acc_fake_tot = disc_acc_fake_tot/x_train_pt.size(0)\n",
        "    disc_acc_tot = np.mean([disc_acc_real_tot, disc_acc_fake_tot])\n",
        "    return gen_loss_tot, disc_loss_tot, disc_acc_tot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F-ILomMn065-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "bf31db6a-3f6d-4c0a-93e7-d4a4564e963d"
      },
      "source": [
        "train_losses_generator_pt = []\n",
        "train_losses_discriminator_pt = []\n",
        "train_acc_discriminator_pt = []\n",
        "epochs = 15\n",
        "start = time.time()\n",
        "for epoch in range(epochs):\n",
        "    gen_loss, disc_loss, disc_acc = train_step_pt(generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
        "    gen_loss = np.mean(gen_loss)\n",
        "    disc_loss = np.mean(disc_loss)\n",
        "    train_losses_generator_pt.append(gen_loss)\n",
        "    train_losses_discriminator_pt.append(disc_loss)\n",
        "    train_acc_discriminator_pt.append(disc_acc*100)\n",
        "\n",
        "\n",
        "    template = (\"Epoch {}, Loss_Generator: {}, Loss_Discriminator: {}, Discriminator_Accuracy: {}\")\n",
        "    print(template.format(epoch+1, gen_loss, disc_loss, disc_acc*100))\n",
        "end = time.time()\n",
        "print(f\"Total training time{start-end}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-494b206f1e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-c6f76db1dd14>\u001b[0m in \u001b[0;36mtrain_step_pt\u001b[0;34m(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdisc_loss_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake_batch_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdisc_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_discriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    840\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    841\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Mbb_M065-"
      },
      "source": [
        "### b) Training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8-7QBvL065_"
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(train_acc_discriminator_pt)\n",
        "plt.title('discriminator accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['discriminator_train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8W0zvk065_"
      },
      "source": [
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(train_losses_generator_pt)\n",
        "plt.plot(train_losses_discriminator_pt)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['generator', 'discriminator'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdVnypYA065_"
      },
      "source": [
        "### c1) Generator output before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMDDynAD066A"
      },
      "source": [
        "fake_im_not_trained = fake_im_not_trained.detach().numpy() * 255\n",
        "fake_im_not_trained = fake_im_not_trained.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im_not_trained, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3KjkI-066A"
      },
      "source": [
        "### c2) Generator output after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfqPBgZo066A"
      },
      "source": [
        "seed2 = torch.rand([1, 100, 1, 1])\n",
        "generator.train(False)\n",
        "fake_im = generator(seed2)\n",
        "fake_im = fake_im.detach().numpy() * 255\n",
        "fake_im = fake_im.reshape((28,28))\n",
        "plt.figure()\n",
        "plt.imshow(fake_im, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}